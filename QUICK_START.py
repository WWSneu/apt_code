#!/usr/bin/env python3
"""
å¿«é€Ÿå¼€å§‹: Qwen2-VL Patch Selection

æœ¬è„šæœ¬å±•ç¤ºå¦‚ä½•åœ¨modelingä¸­é€‰æ‹©patchåˆ’åˆ†æ–¹æ³•å’Œä¼ å…¥alphaå‚æ•°çš„ä¸‰ç§æœ€å¸¸è§æ–¹å¼ã€‚
"""

import sys
sys.path.insert(0, 'Qwen2-VL/transformers/src')

def example1_direct_processor():
    """ä¾‹å­1: ç›´æ¥åˆ›å»ºå’Œä½¿ç”¨ImageProcessor"""
    print("\n" + "="*70)
    print("ä¾‹å­1: ç›´æ¥ä½¿ç”¨Qwen2VLImageProcessor")
    print("="*70)
    
    from transformers.models.qwen2_vl.image_processing_qwen2_vl import Qwen2VLImageProcessor
    import numpy as np
    from PIL import Image
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    test_image = Image.fromarray(
        np.random.randint(0, 256, (224, 224, 3), dtype=np.uint8)
    )
    
    print("\n1ï¸âƒ£  åˆ›å»ºprocessorï¼ŒæŒ‡å®šæ–¹æ³•å’Œalpha:")
    processor = Qwen2VLImageProcessor(
        patch_selection_method='budget',
        alpha=0.3
    )
    print(f"   processor.patch_selection_method = '{processor.patch_selection_method}'")
    print(f"   processor.alpha = {processor.alpha}")
    
    print("\n2ï¸âƒ£  ä½¿ç”¨processorå¤„ç†å›¾åƒ:")
    try:
        # æ³¨æ„: å®é™…å¤„ç†éœ€è¦åœ¨GPUä¸Šï¼Œè¿™é‡Œåªæ˜¯æ¼”ç¤ºè°ƒç”¨æ–¹å¼
        print("   result = processor(images=image_list)")
        print("   â†’ ä¼šåœ¨_preprocessä¸­è°ƒç”¨PatchTokenizer")
        print("   â†’ PatchTokenizerç”¨patch_selection_method='budget', alpha=0.3")
    except Exception as e:
        print(f"   (è·³è¿‡å®é™…æ‰§è¡Œ: {type(e).__name__})")
    
    print("\n3ï¸âƒ£  åœ¨è°ƒç”¨æ—¶è¦†ç›–å‚æ•°:")
    print("""   result = processor(
       images=image_list,
       patch_selection_method='v2',
       alpha=0.5
   )""")


def example2_qwen2vl_processor():
    """ä¾‹å­2: é€šè¿‡Qwen2VLProcessorä¼ é€’å‚æ•°"""
    print("\n" + "="*70)
    print("ä¾‹å­2: é€šè¿‡Qwen2VLProcessorä½¿ç”¨(æ¨è)")
    print("="*70)
    
    print("""
âœ¨ å…³é”®ç‚¹: é€šè¿‡ images_kwargs å‚æ•°ä¼ é€’patché€‰æ‹©é…ç½®

from transformers import Qwen2VLProcessor

processor = Qwen2VLProcessor.from_pretrained("Qwen/Qwen2-VL-7B")

outputs = processor(
    images=image,
    text="Describe this image",
    images_kwargs={
        'patch_selection_method': 'budget',  # é€‰æ‹©æ–¹æ³•
        'alpha': 0.3                         # ä¼ å…¥å‚æ•°
    }
)

# outputs åŒ…å«:
#   - input_ids: æ–‡æœ¬token
#   - pixel_values: å¤„ç†åçš„patches  â† å·²æ ¹æ®budgetæ¨¡å¼é€‰æ‹©
#   - image_grid_thw: å›¾åƒç½‘æ ¼å°ºå¯¸
#   - attention_mask: token mask
    """)


def example3_model_inference():
    """ä¾‹å­3: åœ¨æ¨¡å‹æ¨ç†ä¸­ä½¿ç”¨"""
    print("\n" + "="*70)
    print("ä¾‹å­3: æ¨¡å‹æ¨ç†æµç¨‹")
    print("="*70)
    
    print("""
import torch
from transformers import Qwen2VLProcessor, Qwen2VLForConditionalGeneration

# 1ï¸âƒ£  åŠ è½½æ¨¡å‹
processor = Qwen2VLProcessor.from_pretrained("Qwen/Qwen2-VL-7B")
model = Qwen2VLForConditionalGeneration.from_pretrained("Qwen/Qwen2-VL-7B")
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# 2ï¸âƒ£  è®¾ç½®é»˜è®¤patché€‰æ‹©æ–¹æ³•(å¯é€‰)
processor.image_processor.patch_selection_method = 'budget'
processor.image_processor.alpha = 0.3

# 3ï¸âƒ£  å¤„ç†è¾“å…¥(ä½¿ç”¨é»˜è®¤é…ç½®)
inputs = processor(
    images=image,
    text="<|im_start|>user\\n<image>\\nDescribe this image<|im_end|>\\n<|im_start|>assistant\\n",
    return_tensors='pt'
)

# 4ï¸âƒ£  æˆ–è€…åœ¨å¤„ç†æ—¶è¦†ç›–é…ç½®
inputs = processor(
    images=image,
    text=prompt,
    images_kwargs={
        'patch_selection_method': 'v2',  # ä½¿ç”¨v2æ–¹æ³•
        'alpha': 0.7                      # å‚æ•°è°ƒæ•´
    },
    return_tensors='pt'
)

# 5ï¸âƒ£  ç§»åˆ°GPUå¹¶æ¨ç†
inputs = {k: v.to(device) for k, v in inputs.items()}

with torch.no_grad():
    output_ids = model.generate(
        **inputs,
        max_new_tokens=256,
        temperature=0.7
    )

# 6ï¸âƒ£  è§£ç è¾“å‡º
response = processor.tokenizer.decode(output_ids[0], skip_special_tokens=True)
print(response)
    """)


def example4_comparison():
    """ä¾‹å­4: ä¸åŒæ–¹æ³•çš„å¯¹æ¯”"""
    print("\n" + "="*70)
    print("ä¾‹å­4: ä¸‰ç§æ–¹æ³•çš„æ•ˆæœå¯¹æ¯”")
    print("="*70)
    
    print("""
å‡è®¾è¾“å…¥å›¾åƒä¸º 224Ã—224ï¼Œå¤„ç†æµç¨‹:

â”Œâ”€ åŸå§‹patches: 256 ä¸ª (16Ã—16ç½‘æ ¼)
â”‚
â”œâ”€ v1 æ–¹æ³• (å›ºå®šé˜ˆå€¼ [3, 2])
â”‚  â””â”€ æ ¹æ®ç†µå€¼å‰ªæ
â”‚  â””â”€ å…¸å‹ç»“æœ: ~200-230 ä¸ªpatches
â”‚  â””â”€ ç”¨é€”: åŸºå‡†æ–¹æ¡ˆã€å‘åå…¼å®¹
â”‚
â”œâ”€ v2 æ–¹æ³• (åŠ¨æ€é˜ˆå€¼ = alpha Ã— mean(entropy))
â”‚  â”œâ”€ alpha=0.5: ç»“æœ ~100-150 ä¸ªpatches (åŠ é€Ÿ2-3å€)
â”‚  â”œâ”€ alpha=1.0: ç»“æœ ~150-200 ä¸ªpatches (åŠ é€Ÿ1.3-1.8å€)
â”‚  â””â”€ alpha=1.5: ç»“æœ ~200-230 ä¸ªpatches (åŠ é€Ÿ1.1å€)
â”‚
â””â”€ budget æ–¹æ³• (ç²¾ç¡®é¢„ç®— = round(alpha Ã— 196))
   â”œâ”€ alpha=0.2: budget=39 patches (åŠ é€Ÿ2.5å€)
   â”œâ”€ alpha=0.3: budget=59 patches (åŠ é€Ÿ2.0å€)  â† æ¨è
   â”œâ”€ alpha=0.5: budget=98 patches (åŠ é€Ÿ1.3å€)
   â””â”€ alpha=0.7: budget=137 patches (åŠ é€Ÿ1.1å€)

æ¨èè®¾ç½®:
  é€Ÿåº¦ä¼˜å…ˆ: budget + alpha=0.2 æˆ– 0.3
  è´¨é‡ä¼˜å…ˆ: budget + alpha=0.5 æˆ– v2 + alpha=1.0
  å¹³è¡¡æ–¹æ¡ˆ: budget + alpha=0.3 (é»˜è®¤æ¨è)
    """)


def example5_debugging():
    """ä¾‹å­5: è°ƒè¯•å’Œç›‘æ§"""
    print("\n" + "="*70)
    print("ä¾‹å­5: è°ƒè¯•å’Œæ€§èƒ½ç›‘æ§")
    print("="*70)
    
    print("""
å½“ä½¿ç”¨ budget æ¨¡å¼æ—¶ï¼Œå¯ä»¥è·å–è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯:

from transformers import Qwen2VLProcessor

processor = Qwen2VLProcessor.from_pretrained("Qwen/Qwen2-VL-7B")

# å¤„ç†å›¾åƒ
outputs = processor(
    images=image,
    text=prompt,
    images_kwargs={
        'patch_selection_method': 'budget',
        'alpha': 0.3
    }
)

# è·å–PatchTokenizerçš„ç»Ÿè®¡ä¿¡æ¯
image_proc = processor.image_processor
if hasattr(image_proc, 'last_budget_info'):
    info = image_proc.last_budget_info
    print(f"åŸºç¡€tokens (L3): {info['base_tokens']}")
    print(f"æœ€å°patchæ€»æ•° (L1): {info['base_small_tokens']}")
    print(f"åˆ†é…é¢„ç®—: {info['budget']}")
    print(f"æ¯å±‚é¢å¤–patches: {info['k']}")
    print(f"å®é™…é€‰æ‹©æ•°: {info['actual']}")
    
    # è®¡ç®—å®é™…ä¿ç•™ç‡
    retention_rate = info['actual'] / (info['base_small_tokens'] * 3) * 100
    print(f"å®é™…ä¿ç•™ç‡: {retention_rate:.2f}%")

# æ€§èƒ½ç›‘æ§
import time
start = time.time()
outputs = processor(images=image, text=prompt, ...)
preprocess_time = time.time() - start
print(f"å¤„ç†è€—æ—¶: {preprocess_time:.3f}ç§’")
    """)


def summary():
    """æ€»ç»“"""
    print("\n" + "="*70)
    print("æ€»ç»“: ä¸‰ç§å‚æ•°ä¼ é€’æ–¹å¼")
    print("="*70)
    
    print("""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     å‚æ•°ä¼ é€’æ–¹å¼                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                       â”‚
â”‚ æ–¹å¼1: ImageProcessor æ„é€ æ—¶æŒ‡å®š                                    â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                           â”‚
â”‚   processor = Qwen2VLImageProcessor(                                â”‚
â”‚       patch_selection_method='budget',                              â”‚
â”‚       alpha=0.3                                                      â”‚
â”‚   )                                                                   â”‚
â”‚                                                                       â”‚
â”‚ æ–¹å¼2: åœ¨è°ƒç”¨æ—¶é€šè¿‡ images_kwargs è¦†ç›– (æ¨è)                       â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                    â”‚
â”‚   outputs = processor(                                               â”‚
â”‚       images=image,                                                  â”‚
â”‚       text=prompt,                                                   â”‚
â”‚       images_kwargs={                                                â”‚
â”‚           'patch_selection_method': 'budget',                        â”‚
â”‚           'alpha': 0.3                                               â”‚
â”‚       }                                                               â”‚
â”‚   )                                                                   â”‚
â”‚                                                                       â”‚
â”‚ æ–¹å¼3: ä¿®æ”¹processorå±æ€§è®¾ç½®é»˜è®¤å€¼                                   â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                â”‚
â”‚   processor.image_processor.patch_selection_method = 'budget'       â”‚
â”‚   processor.image_processor.alpha = 0.3                             â”‚
â”‚   # ä¹‹åçš„è°ƒç”¨éƒ½ä½¿ç”¨è¿™äº›é»˜è®¤å€¼                                       â”‚
â”‚                                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âœ¨ æ¨èå·¥ä½œæµ:

1. å¯¹äºç”Ÿäº§æ¨ç†:
   processor.image_processor.patch_selection_method = 'budget'
   processor.image_processor.alpha = 0.3
   
2. å¯¹äºå®éªŒå¯¹æ¯”:
   outputs_v1 = processor(..., images_kwargs={'patch_selection_method': 'v1'})
   outputs_v2 = processor(..., images_kwargs={'patch_selection_method': 'v2', 'alpha': 0.5})
   outputs_budget = processor(..., images_kwargs={'patch_selection_method': 'budget', 'alpha': 0.3})
   
3. å¯¹äºåŠ¨æ€è°ƒæ•´:
   for alpha in [0.2, 0.3, 0.5, 0.7]:
       outputs = processor(..., images_kwargs={'patch_selection_method': 'budget', 'alpha': alpha})
    """)


if __name__ == "__main__":
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                       â•‘
â•‘  Qwen2-VL Patch Selection - å¿«é€Ÿå¼€å§‹æŒ‡å—                            â•‘
â•‘                                                                       â•‘
â•‘  ä¸‰ç§æ–¹æ³•: v1 (å›ºå®š) / v2 (åŠ¨æ€) / budget (é¢„ç®—)                    â•‘
â•‘  æ ¸å¿ƒé—®é¢˜: å¦‚ä½•é€‰æ‹©æ–¹æ³•ï¼Ÿå¦‚ä½•ä¼ å…¥alphaå‚æ•°ï¼Ÿ                        â•‘
â•‘                                                                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    example1_direct_processor()
    example2_qwen2vl_processor()
    example3_model_inference()
    example4_comparison()
    example5_debugging()
    summary()
    
    print("\nğŸ“š æ›´å¤šä¿¡æ¯:")
    print("  - è¯¦ç»†æ–‡æ¡£: PATCH_SELECTION_USAGE.md")
    print("  - å¿«é€Ÿå‚è€ƒ: PATCH_SELECTION_QUICKREF.md")
    print("  - å®ç°ç»†èŠ‚: PATCH_SELECTION_IMPLEMENTATION.md")
    print("  - å®Œæ•´æ¼”ç¤º: python demo_patch_selection.py")
    print()
