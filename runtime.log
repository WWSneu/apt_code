Requirement already satisfied: qwen_vl_utils in /mnt/users/zhujiayi-20251002/conda/envs/apt/lib/python3.10/site-packages (0.0.14)
Requirement already satisfied: av in /mnt/users/zhujiayi-20251002/conda/envs/apt/lib/python3.10/site-packages (from qwen_vl_utils) (16.0.1)
Requirement already satisfied: packaging in /mnt/users/zhujiayi-20251002/conda/envs/apt/lib/python3.10/site-packages (from qwen_vl_utils) (25.0)
Requirement already satisfied: pillow in /mnt/users/zhujiayi-20251002/conda/envs/apt/lib/python3.10/site-packages (from qwen_vl_utils) (12.0.0)
Requirement already satisfied: requests in /mnt/users/zhujiayi-20251002/conda/envs/apt/lib/python3.10/site-packages (from qwen_vl_utils) (2.32.5)
Requirement already satisfied: charset_normalizer<4,>=2 in /mnt/users/zhujiayi-20251002/conda/envs/apt/lib/python3.10/site-packages (from requests->qwen_vl_utils) (3.4.4)
Requirement already satisfied: idna<4,>=2.5 in /mnt/users/zhujiayi-20251002/conda/envs/apt/lib/python3.10/site-packages (from requests->qwen_vl_utils) (3.11)
Requirement already satisfied: urllib3<3,>=1.21.1 in /mnt/users/zhujiayi-20251002/conda/envs/apt/lib/python3.10/site-packages (from requests->qwen_vl_utils) (2.5.0)
Requirement already satisfied: certifi>=2017.4.17 in /mnt/users/zhujiayi-20251002/conda/envs/apt/lib/python3.10/site-packages (from requests->qwen_vl_utils) (2025.10.5)
[32m2025-11-22 21:33:05.147[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m301[0m - [1mVerbosity set to INFO[0m
[32m2025-11-22 21:33:05.175[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m301[0m - [1mVerbosity set to INFO[0m
[32m2025-11-22 21:33:05.187[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m301[0m - [1mVerbosity set to INFO[0m
[32m2025-11-22 21:33:05.189[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m301[0m - [1mVerbosity set to INFO[0m
[32m2025-11-22 21:33:08.844[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m391[0m - [1mEvaluation tracker args: {'output_path': './logs/'}[0m
[32m2025-11-22 21:33:08.845[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m480[0m - [1mSelected Tasks: ['mmstar'][0m
[32m2025-11-22 21:33:08.847[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m158[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
[32m2025-11-22 21:33:08.852[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m391[0m - [1mEvaluation tracker args: {'output_path': './logs/'}[0m
[32m2025-11-22 21:33:08.852[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m480[0m - [1mSelected Tasks: ['mmstar'][0m
[32m2025-11-22 21:33:08.854[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m158[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
[32m2025-11-22 21:33:08.935[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m391[0m - [1mEvaluation tracker args: {'output_path': './logs/'}[0m
[32m2025-11-22 21:33:08.935[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m480[0m - [1mSelected Tasks: ['mmstar'][0m
[32m2025-11-22 21:33:08.937[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m158[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
[32m2025-11-22 21:33:08.965[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m391[0m - [1mEvaluation tracker args: {'output_path': './logs/'}[0m
[32m2025-11-22 21:33:08.965[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m480[0m - [1mSelected Tasks: ['mmstar'][0m
[32m2025-11-22 21:33:08.967[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m158[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
ðŸš¨ `output_dict` is part of Qwen2VLModel.forward's signature, but not documented. Make sure to add it to the docstring of the function in /data/zhujiayi-20251002/workspace/llava-apt/APT_eval/Qwen2-VL/transformers/src/transformers/models/qwen2_vl/modeling_qwen2_vl.py.
ðŸš¨ `images_output` is part of Qwen2VLModel.forward's signature, but not documented. Make sure to add it to the docstring of the function in /data/zhujiayi-20251002/workspace/llava-apt/APT_eval/Qwen2-VL/transformers/src/transformers/models/qwen2_vl/modeling_qwen2_vl.py.
ðŸš¨ `output_dict` is part of Qwen2VLForConditionalGeneration.forward's signature, but not documented. Make sure to add it to the docstring of the function in /data/zhujiayi-20251002/workspace/llava-apt/APT_eval/Qwen2-VL/transformers/src/transformers/models/qwen2_vl/modeling_qwen2_vl.py.
ðŸš¨ `images_output` is part of Qwen2VLForConditionalGeneration.forward's signature, but not documented. Make sure to add it to the docstring of the function in /data/zhujiayi-20251002/workspace/llava-apt/APT_eval/Qwen2-VL/transformers/src/transformers/models/qwen2_vl/modeling_qwen2_vl.py.
ðŸš¨ `output_dict` is part of Qwen2VLModel.forward's signature, but not documented. Make sure to add it to the docstring of the function in /data/zhujiayi-20251002/workspace/llava-apt/APT_eval/Qwen2-VL/transformers/src/transformers/models/qwen2_vl/modeling_qwen2_vl.py.
ðŸš¨ `images_output` is part of Qwen2VLModel.forward's signature, but not documented. Make sure to add it to the docstring of the function in /data/zhujiayi-20251002/workspace/llava-apt/APT_eval/Qwen2-VL/transformers/src/transformers/models/qwen2_vl/modeling_qwen2_vl.py.
ðŸš¨ `output_dict` is part of Qwen2VLForConditionalGeneration.forward's signature, but not documented. Make sure to add it to the docstring of the function in /data/zhujiayi-20251002/workspace/llava-apt/APT_eval/Qwen2-VL/transformers/src/transformers/models/qwen2_vl/modeling_qwen2_vl.py.
ðŸš¨ `images_output` is part of Qwen2VLForConditionalGeneration.forward's signature, but not documented. Make sure to add it to the docstring of the function in /data/zhujiayi-20251002/workspace/llava-apt/APT_eval/Qwen2-VL/transformers/src/transformers/models/qwen2_vl/modeling_qwen2_vl.py.
ðŸš¨ `output_dict` is part of Qwen2VLModel.forward's signature, but not documented. Make sure to add it to the docstring of the function in /data/zhujiayi-20251002/workspace/llava-apt/APT_eval/Qwen2-VL/transformers/src/transformers/models/qwen2_vl/modeling_qwen2_vl.py.
ðŸš¨ `images_output` is part of Qwen2VLModel.forward's signature, but not documented. Make sure to add it to the docstring of the function in /data/zhujiayi-20251002/workspace/llava-apt/APT_eval/Qwen2-VL/transformers/src/transformers/models/qwen2_vl/modeling_qwen2_vl.py.
ðŸš¨ `output_dict` is part of Qwen2VLForConditionalGeneration.forward's signature, but not documented. Make sure to add it to the docstring of the function in /data/zhujiayi-20251002/workspace/llava-apt/APT_eval/Qwen2-VL/transformers/src/transformers/models/qwen2_vl/modeling_qwen2_vl.py.
ðŸš¨ `images_output` is part of Qwen2VLForConditionalGeneration.forward's signature, but not documented. Make sure to add it to the docstring of the function in /data/zhujiayi-20251002/workspace/llava-apt/APT_eval/Qwen2-VL/transformers/src/transformers/models/qwen2_vl/modeling_qwen2_vl.py.
ðŸš¨ `output_dict` is part of Qwen2VLModel.forward's signature, but not documented. Make sure to add it to the docstring of the function in /data/zhujiayi-20251002/workspace/llava-apt/APT_eval/Qwen2-VL/transformers/src/transformers/models/qwen2_vl/modeling_qwen2_vl.py.
ðŸš¨ `images_output` is part of Qwen2VLModel.forward's signature, but not documented. Make sure to add it to the docstring of the function in /data/zhujiayi-20251002/workspace/llava-apt/APT_eval/Qwen2-VL/transformers/src/transformers/models/qwen2_vl/modeling_qwen2_vl.py.
ðŸš¨ `output_dict` is part of Qwen2VLForConditionalGeneration.forward's signature, but not documented. Make sure to add it to the docstring of the function in /data/zhujiayi-20251002/workspace/llava-apt/APT_eval/Qwen2-VL/transformers/src/transformers/models/qwen2_vl/modeling_qwen2_vl.py.
ðŸš¨ `images_output` is part of Qwen2VLForConditionalGeneration.forward's signature, but not documented. Make sure to add it to the docstring of the function in /data/zhujiayi-20251002/workspace/llava-apt/APT_eval/Qwen2-VL/transformers/src/transformers/models/qwen2_vl/modeling_qwen2_vl.py.
[32m2025-11-22 21:33:36.524[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36m__init__[0m:[36m89[0m - [1mForwarded patch_selection_method=None, alpha=None[0m
[32m2025-11-22 21:33:36.575[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36m__init__[0m:[36m89[0m - [1mForwarded patch_selection_method=None, alpha=None[0m
[32m2025-11-22 21:33:38.359[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for mmstar, using default n_shot=0[0m
[32m2025-11-22 21:33:38.359[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for mmstar on rank 1...[0m
[32m2025-11-22 21:33:38.533[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36m__init__[0m:[36m127[0m - [1mUsing 4 devices with data parallelism[0m
[32m2025-11-22 21:33:38.533[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for mmstar, using default n_shot=0[0m
[32m2025-11-22 21:33:38.534[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for mmstar on rank 0...[0m
[32m2025-11-22 21:33:38.964[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36m__init__[0m:[36m89[0m - [1mForwarded patch_selection_method=None, alpha=None[0m
[32m2025-11-22 21:33:40.738[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36m__init__[0m:[36m89[0m - [1mForwarded patch_selection_method=None, alpha=None[0m
[32m2025-11-22 21:33:40.824[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for mmstar, using default n_shot=0[0m
[32m2025-11-22 21:33:40.825[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for mmstar on rank 3...[0m
[32m2025-11-22 21:33:42.316[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for mmstar, using default n_shot=0[0m
[32m2025-11-22 21:33:42.317[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m425[0m - [1mBuilding contexts for mmstar on rank 2...[0m
[32m2025-11-22 21:33:42.772[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m465[0m - [1mRunning generate_until requests[0m
[32m2025-11-22 21:33:42.772[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m465[0m - [1mRunning generate_until requests[0m
[32m2025-11-22 21:33:42.772[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m465[0m - [1mRunning generate_until requests[0m
[32m2025-11-22 21:33:42.772[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m465[0m - [1mRunning generate_until requests[0m
[32m2025-11-22 21:33:42.997[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 16[0m
[32m2025-11-22 21:33:42.997[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 112x308 (176 patches), Resized: 112x336 (192 patches), Final APT: 16 patches[0m
[32m2025-11-22 21:33:43.004[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:43.093[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:43.093[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:43.144[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 48[0m
[32m2025-11-22 21:33:43.144[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 196x448 (448 patches), Resized: 224x448 (512 patches), Final APT: 48 patches[0m
[32m2025-11-22 21:33:43.157[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:43.226[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:43.226[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:43.308[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[1, 4, 4]]) after filter[0m
[32m2025-11-22 21:33:43.309[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 369]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 369])[0m
[32m2025-11-22 21:33:43.309[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[1, 4, 4]])[0m
[32m2025-11-22 21:33:43.349[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:43.349[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 4]), pos:tensor([[0, 0, 0, 0],
        [0, 0, 1, 1],
        [0, 1, 0, 1]])[0m
[32m2025-11-22 21:33:43.350[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 369]), llm_positions:tensor([[  0,   1,   2,  ..., 364, 365, 366],
        [  0,   1,   2,  ..., 364, 365, 366],
        [  0,   1,   2,  ..., 364, 365, 366]])[0m
[32m2025-11-22 21:33:43.350[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:43.357[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:43.424[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[1, 6, 8]]) after filter[0m
[32m2025-11-22 21:33:43.424[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 510]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 510])[0m
[32m2025-11-22 21:33:43.424[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[1, 6, 8]])[0m
[32m2025-11-22 21:33:43.458[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:43.459[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 12]), pos:tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2],
        [0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3]])[0m
[32m2025-11-22 21:33:43.459[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 510]), llm_positions:tensor([[  0,   1,   2,  ..., 499, 500, 501],
        [  0,   1,   2,  ..., 499, 500, 501],
        [  0,   1,   2,  ..., 499, 500, 501]])[0m
[32m2025-11-22 21:33:43.460[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:43.465[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:43.493[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 92[0m
[32m2025-11-22 21:33:43.493[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 336x504 (864 patches), Resized: 336x504 (864 patches), Final APT: 92 patches[0m
[32m2025-11-22 21:33:43.513[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:43.587[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 16[0m
[32m2025-11-22 21:33:43.587[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([16, 1280])[0m
[32m2025-11-22 21:33:43.587[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[1, 4, 4]], device='cuda:2')[0m
[32m2025-11-22 21:33:43.587[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1,  8, 24]], device='cuda:2')[0m
[32m2025-11-22 21:33:43.616[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:43.616[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:43.706[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 48[0m
[32m2025-11-22 21:33:43.706[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([48, 1280])[0m
[32m2025-11-22 21:33:43.706[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[1, 6, 8]], device='cuda:3')[0m
[32m2025-11-22 21:33:43.707[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1, 16, 32]], device='cuda:3')[0m
[32m2025-11-22 21:33:43.812[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:43.824[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[ 1,  2, 46]]) after filter[0m
[32m2025-11-22 21:33:43.824[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 299]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 299])[0m
[32m2025-11-22 21:33:43.824[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[ 1,  2, 46]])[0m
[32m2025-11-22 21:33:43.843[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:43.855[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:43.856[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 23]), pos:tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0],
        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22]])[0m
[32m2025-11-22 21:33:43.860[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 299]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,
         168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,
         182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,
         196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,
         210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,
         224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,
         238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,
         252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,
         266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,
         280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,
         294, 295, 296, 297, 298],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,
         168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,
         182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,
         196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,
         210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,
         224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,
         238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,
         252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,
         266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,
         280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,
         294, 295, 296, 297, 298],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,
         168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,
         182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,
         196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,
         210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,
         224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,
         238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,
         252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,
         266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,
         280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,
         294, 295, 296, 297, 298]])[0m
[32m2025-11-22 21:33:43.861[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:43.866[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:43.883[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:43.885[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:43.945[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:43.975[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:44.014[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:44.015[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:44.161[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 92[0m
[32m2025-11-22 21:33:44.161[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([92, 1280])[0m
[32m2025-11-22 21:33:44.162[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[ 1,  2, 46]], device='cuda:0')[0m
[32m2025-11-22 21:33:44.162[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1, 24, 36]], device='cuda:0')[0m
[32m2025-11-22 21:33:44.287[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 48[0m
[32m2025-11-22 21:33:44.287[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 168x504 (432 patches), Resized: 168x504 (432 patches), Final APT: 48 patches[0m
[32m2025-11-22 21:33:44.296[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:44.301[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:44.301[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:44.301[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[1, 6, 8]]) after filter[0m
[32m2025-11-22 21:33:44.301[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 241]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 241])[0m
[32m2025-11-22 21:33:44.302[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[1, 6, 8]])[0m
[32m2025-11-22 21:33:44.302[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:44.303[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 12]), pos:tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2],
        [0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3]])[0m
[32m2025-11-22 21:33:44.306[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 241]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  19,
          20,  21,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,
          34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,
          48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,
          62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,
          76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,
          90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,
         104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,
         118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,
         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
         146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
         160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173,
         174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187,
         188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201,
         202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215,
         216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229,
         230, 231, 232],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  16,  16,  16,  16,  17,  17,  17,  17,  19,
          20,  21,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,
          34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,
          48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,
          62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,
          76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,
          90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,
         104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,
         118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,
         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
         146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
         160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173,
         174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187,
         188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201,
         202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215,
         216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229,
         230, 231, 232],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  15,  16,  17,  18,  15,  16,  17,  18,  19,
          20,  21,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,
          34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,
          48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,
          62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,
          76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,
          90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,
         104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,
         118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,
         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
         146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
         160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173,
         174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187,
         188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201,
         202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215,
         216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229,
         230, 231, 232]])[0m
[32m2025-11-22 21:33:44.306[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:44.306[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:44.345[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 48[0m
[32m2025-11-22 21:33:44.346[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([48, 1280])[0m
[32m2025-11-22 21:33:44.346[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[1, 6, 8]], device='cuda:3')[0m
[32m2025-11-22 21:33:44.347[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1, 12, 36]], device='cuda:3')[0m
[32m2025-11-22 21:33:44.389[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:44.395[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:44.404[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:44.416[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:44.427[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:44.428[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:44.455[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:44.457[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:44.576[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 108[0m
[32m2025-11-22 21:33:44.576[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 420x476 (1020 patches), Resized: 448x504 (1152 patches), Final APT: 108 patches[0m
[32m2025-11-22 21:33:44.597[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:44.601[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:44.601[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:44.601[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[ 1,  6, 18]]) after filter[0m
[32m2025-11-22 21:33:44.601[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 252]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 252])[0m
[32m2025-11-22 21:33:44.601[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[ 1,  6, 18]])[0m
[32m2025-11-22 21:33:44.603[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:44.603[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 27]), pos:tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2,
         2, 2, 2],
        [0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 1, 2, 3, 4, 5,
         6, 7, 8]])[0m
[32m2025-11-22 21:33:44.607[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 252]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,
          38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,
          52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,
          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,
          80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,
          94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,
         108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,
         122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135,
         136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
         150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,
         164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177,
         178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191,
         192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,
         206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,
         220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  15,  15,  16,  16,  16,  16,
          16,  16,  16,  16,  16,  17,  17,  17,  17,  17,  17,  17,  17,  17,
          24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,
          38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,
          52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,
          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,
          80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,
          94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,
         108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,
         122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135,
         136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
         150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,
         164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177,
         178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191,
         192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,
         206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,
         220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  15,  16,  17,  18,
          19,  20,  21,  22,  23,  15,  16,  17,  18,  19,  20,  21,  22,  23,
          24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,
          38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,
          52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,
          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,
          80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,
          94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,
         108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,
         122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135,
         136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
         150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,
         164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177,
         178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191,
         192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,
         206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,
         220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233]])[0m
[32m2025-11-22 21:33:44.608[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:44.608[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:44.612[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 28[0m
[32m2025-11-22 21:33:44.612[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 112x504 (288 patches), Resized: 112x504 (288 patches), Final APT: 28 patches[0m
[32m2025-11-22 21:33:44.619[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:44.621[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:44.621[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:44.622[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[ 1,  2, 14]]) after filter[0m
[32m2025-11-22 21:33:44.622[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 219]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 219])[0m
[32m2025-11-22 21:33:44.622[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[ 1,  2, 14]])[0m
[32m2025-11-22 21:33:44.622[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:44.623[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 7]), pos:tensor([[0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0],
        [0, 1, 2, 3, 4, 5, 6]])[0m
[32m2025-11-22 21:33:44.626[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 219]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,
         168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,
         182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,
         196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,
         210, 211, 212, 213, 214, 215, 216, 217, 218],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,
         168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,
         182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,
         196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,
         210, 211, 212, 213, 214, 215, 216, 217, 218],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,
         168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,
         182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,
         196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,
         210, 211, 212, 213, 214, 215, 216, 217, 218]])[0m
[32m2025-11-22 21:33:44.626[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:44.626[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:44.653[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 28[0m
[32m2025-11-22 21:33:44.653[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 32[0m
[32m2025-11-22 21:33:44.653[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 224x252 (288 patches), Resized: 224x280 (320 patches), Final APT: 32 patches[0m
[32m2025-11-22 21:33:44.653[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([28, 1280])[0m
[32m2025-11-22 21:33:44.654[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[ 1,  2, 14]], device='cuda:3')[0m
[32m2025-11-22 21:33:44.654[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1,  8, 36]], device='cuda:3')[0m
[32m2025-11-22 21:33:44.661[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:44.666[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:44.666[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:44.666[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[1, 4, 8]]) after filter[0m
[32m2025-11-22 21:33:44.666[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 263]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 263])[0m
[32m2025-11-22 21:33:44.666[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[1, 4, 8]])[0m
[32m2025-11-22 21:33:44.669[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:44.669[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 8]), pos:tensor([[0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 1, 1, 1],
        [0, 1, 2, 3, 0, 1, 2, 3]])[0m
[32m2025-11-22 21:33:44.672[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 263]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  15,  19,  20,  21,  22,  23,
          24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,
          38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,
          52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,
          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,
          80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,
          94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,
         108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,
         122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135,
         136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
         150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,
         164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177,
         178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191,
         192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,
         206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,
         220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,
         234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,
         248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  16,  16,  16,  16,  19,  20,  21,  22,  23,
          24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,
          38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,
          52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,
          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,
          80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,
          94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,
         108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,
         122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135,
         136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
         150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,
         164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177,
         178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191,
         192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,
         206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,
         220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,
         234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,
         248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  15,  16,  17,  18,  19,  20,  21,  22,  23,
          24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,
          38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,
          52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,
          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,
          80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,
          94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,
         108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,
         122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135,
         136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
         150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,
         164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177,
         178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191,
         192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,
         206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,
         220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,
         234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,
         248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258]])[0m
[32m2025-11-22 21:33:44.673[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:44.673[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:44.702[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 32[0m
[32m2025-11-22 21:33:44.702[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([32, 1280])[0m
[32m2025-11-22 21:33:44.702[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[1, 4, 8]], device='cuda:0')[0m
[32m2025-11-22 21:33:44.702[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1, 16, 20]], device='cuda:0')[0m
[32m2025-11-22 21:33:44.716[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:44.716[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 108[0m
[32m2025-11-22 21:33:44.717[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([108, 1280])[0m
[32m2025-11-22 21:33:44.717[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[ 1,  6, 18]], device='cuda:2')[0m
[32m2025-11-22 21:33:44.717[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1, 32, 36]], device='cuda:2')[0m
[32m2025-11-22 21:33:44.729[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:44.752[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:44.752[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:44.769[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:44.770[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:44.779[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:44.792[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:44.804[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:44.805[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:44.815[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:44.816[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:44.889[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 20[0m
[32m2025-11-22 21:33:44.889[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 196x196 (196 patches), Resized: 224x224 (256 patches), Final APT: 20 patches[0m
[32m2025-11-22 21:33:44.895[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:44.898[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:44.898[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:44.898[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[ 1,  2, 10]]) after filter[0m
[32m2025-11-22 21:33:44.898[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 203]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 203])[0m
[32m2025-11-22 21:33:44.898[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[ 1,  2, 10]])[0m
[32m2025-11-22 21:33:44.899[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:44.899[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 5]), pos:tensor([[0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0],
        [0, 1, 2, 3, 4]])[0m
[32m2025-11-22 21:33:44.902[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 203]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,
         168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,
         182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,
         196, 197, 198, 199, 200, 201, 202],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,
         168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,
         182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,
         196, 197, 198, 199, 200, 201, 202],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,
         168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,
         182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,
         196, 197, 198, 199, 200, 201, 202]])[0m
[32m2025-11-22 21:33:44.903[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:44.903[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:44.926[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 20[0m
[32m2025-11-22 21:33:44.927[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([20, 1280])[0m
[32m2025-11-22 21:33:44.927[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[ 1,  2, 10]], device='cuda:3')[0m
[32m2025-11-22 21:33:44.927[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1, 16, 16]], device='cuda:3')[0m
[32m2025-11-22 21:33:44.978[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:44.990[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:45.013[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:45.013[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 24[0m
[32m2025-11-22 21:33:45.014[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 196x252 (252 patches), Resized: 224x280 (320 patches), Final APT: 24 patches[0m
[32m2025-11-22 21:33:45.014[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:45.021[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:45.024[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:45.024[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:45.025[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[1, 4, 6]]) after filter[0m
[32m2025-11-22 21:33:45.025[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 223]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 223])[0m
[32m2025-11-22 21:33:45.025[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[1, 4, 6]])[0m
[32m2025-11-22 21:33:45.025[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:45.026[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 6]), pos:tensor([[0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 1, 1],
        [0, 1, 2, 0, 1, 2]])[0m
[32m2025-11-22 21:33:45.029[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 223]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  18,  19,  20,  21,  22,  23,  24,
          25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,
          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,
          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,
          67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,
          81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,
          95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108,
         109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122,
         123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136,
         137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
         151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,
         165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178,
         179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192,
         193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206,
         207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  16,  16,  16,  18,  19,  20,  21,  22,  23,  24,
          25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,
          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,
          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,
          67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,
          81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,
          95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108,
         109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122,
         123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136,
         137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
         151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,
         165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178,
         179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192,
         193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206,
         207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,
          25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,
          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,
          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,
          67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,
          81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,
          95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108,
         109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122,
         123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136,
         137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
         151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,
         165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178,
         179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192,
         193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206,
         207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219]])[0m
[32m2025-11-22 21:33:45.030[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:45.030[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:45.061[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 24[0m
[32m2025-11-22 21:33:45.061[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([24, 1280])[0m
[32m2025-11-22 21:33:45.061[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[1, 4, 6]], device='cuda:2')[0m
[32m2025-11-22 21:33:45.062[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1, 16, 20]], device='cuda:2')[0m
[32m2025-11-22 21:33:45.126[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:45.136[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:45.162[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:45.163[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:45.242[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 36[0m
[32m2025-11-22 21:33:45.242[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 224x308 (352 patches), Resized: 224x336 (384 patches), Final APT: 36 patches[0m
[32m2025-11-22 21:33:45.250[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:45.254[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:45.254[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:45.254[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[1, 6, 6]]) after filter[0m
[32m2025-11-22 21:33:45.255[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 202]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 202])[0m
[32m2025-11-22 21:33:45.255[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[1, 6, 6]])[0m
[32m2025-11-22 21:33:45.256[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:45.256[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 9]), pos:tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 1, 1, 2, 2, 2],
        [0, 1, 2, 0, 1, 2, 0, 1, 2]])[0m
[32m2025-11-22 21:33:45.259[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 202]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  15,  15,  18,  19,  20,  21,
          22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,
          36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,
          50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,
          64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,
          78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,
          92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,
         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,
         120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,
         134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
         148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
         162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,
         176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189,
         190, 191, 192, 193, 194, 195],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  16,  16,  16,  17,  17,  17,  18,  19,  20,  21,
          22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,
          36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,
          50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,
          64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,
          78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,
          92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,
         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,
         120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,
         134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
         148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
         162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,
         176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189,
         190, 191, 192, 193, 194, 195],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  15,  16,  17,  15,  16,  17,  18,  19,  20,  21,
          22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,
          36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,
          50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,
          64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,
          78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,
          92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,
         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,
         120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,
         134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
         148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
         162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,
         176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189,
         190, 191, 192, 193, 194, 195]])[0m
[32m2025-11-22 21:33:45.259[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:45.260[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:45.266[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 12[0m
[32m2025-11-22 21:33:45.266[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 56x504 (144 patches), Resized: 56x504 (144 patches), Final APT: 12 patches[0m
[32m2025-11-22 21:33:45.272[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:45.275[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:45.275[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:45.276[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[1, 2, 6]]) after filter[0m
[32m2025-11-22 21:33:45.276[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 189]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 189])[0m
[32m2025-11-22 21:33:45.276[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[1, 2, 6]])[0m
[32m2025-11-22 21:33:45.277[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:45.277[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 3]), pos:tensor([[0, 0, 0],
        [0, 0, 0],
        [0, 1, 2]])[0m
[32m2025-11-22 21:33:45.280[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 189]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,
         168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,
         182, 183, 184, 185, 186, 187, 188],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,
         168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,
         182, 183, 184, 185, 186, 187, 188],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,
         168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,
         182, 183, 184, 185, 186, 187, 188]])[0m
[32m2025-11-22 21:33:45.280[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:45.280[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:45.295[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 12[0m
[32m2025-11-22 21:33:45.295[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 36[0m
[32m2025-11-22 21:33:45.295[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([36, 1280])[0m
[32m2025-11-22 21:33:45.296[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([12, 1280])[0m
[32m2025-11-22 21:33:45.295[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[1, 6, 6]], device='cuda:3')[0m
[32m2025-11-22 21:33:45.296[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[1, 2, 6]], device='cuda:2')[0m
[32m2025-11-22 21:33:45.296[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1, 16, 24]], device='cuda:3')[0m
[32m2025-11-22 21:33:45.296[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1,  4, 36]], device='cuda:2')[0m
[32m2025-11-22 21:33:45.347[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:45.353[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:45.363[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:45.363[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:45.386[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:45.387[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:45.388[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:45.388[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:45.463[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 12[0m
[32m2025-11-22 21:33:45.464[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 112x196 (112 patches), Resized: 112x224 (128 patches), Final APT: 12 patches[0m
[32m2025-11-22 21:33:45.468[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:45.470[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:45.471[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:45.471[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[1, 2, 6]]) after filter[0m
[32m2025-11-22 21:33:45.471[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 169]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 169])[0m
[32m2025-11-22 21:33:45.471[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[1, 2, 6]])[0m
[32m2025-11-22 21:33:45.472[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:45.472[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 3]), pos:tensor([[0, 0, 0],
        [0, 0, 0],
        [0, 1, 2]])[0m
[32m2025-11-22 21:33:45.474[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 169]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,
         168],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,
         168],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,
         168]])[0m
[32m2025-11-22 21:33:45.476[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:45.476[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:45.489[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 12[0m
[32m2025-11-22 21:33:45.490[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([12, 1280])[0m
[32m2025-11-22 21:33:45.490[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[1, 2, 6]], device='cuda:3')[0m
[32m2025-11-22 21:33:45.490[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1,  8, 16]], device='cuda:3')[0m
[32m2025-11-22 21:33:45.541[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:45.548[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:45.571[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:45.572[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:45.636[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 12[0m
[32m2025-11-22 21:33:45.636[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 168x112 (96 patches), Resized: 168x112 (96 patches), Final APT: 12 patches[0m
[32m2025-11-22 21:33:45.639[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:45.642[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:45.642[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:45.642[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[1, 2, 6]]) after filter[0m
[32m2025-11-22 21:33:45.642[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 160]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 160])[0m
[32m2025-11-22 21:33:45.643[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[1, 2, 6]])[0m
[32m2025-11-22 21:33:45.643[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:45.643[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 3]), pos:tensor([[0, 0, 0],
        [0, 0, 0],
        [0, 1, 2]])[0m
[32m2025-11-22 21:33:45.646[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 160]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159]])[0m
[32m2025-11-22 21:33:45.646[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:45.646[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:45.656[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 12[0m
[32m2025-11-22 21:33:45.656[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([12, 1280])[0m
[32m2025-11-22 21:33:45.656[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[1, 2, 6]], device='cuda:3')[0m
[32m2025-11-22 21:33:45.657[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1, 12,  8]], device='cuda:3')[0m
[32m2025-11-22 21:33:45.676[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 48[0m
[32m2025-11-22 21:33:45.677[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 168x504 (432 patches), Resized: 168x504 (432 patches), Final APT: 48 patches[0m
[32m2025-11-22 21:33:45.686[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:45.692[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:45.692[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:45.693[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[1, 6, 8]]) after filter[0m
[32m2025-11-22 21:33:45.693[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 195]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 195])[0m
[32m2025-11-22 21:33:45.693[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[1, 6, 8]])[0m
[32m2025-11-22 21:33:45.693[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:45.694[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 12]), pos:tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2],
        [0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3]])[0m
[32m2025-11-22 21:33:45.697[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 195]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  19,
          20,  21,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,
          34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,
          48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,
          62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,
          76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,
          90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,
         104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,
         118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,
         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
         146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
         160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173,
         174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  16,  16,  16,  16,  17,  17,  17,  17,  19,
          20,  21,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,
          34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,
          48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,
          62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,
          76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,
          90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,
         104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,
         118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,
         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
         146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
         160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173,
         174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  15,  16,  17,  18,  15,  16,  17,  18,  19,
          20,  21,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,
          34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,
          48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,
          62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,
          76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,
          90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,
         104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,
         118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,
         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
         146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
         160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173,
         174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186]])[0m
[32m2025-11-22 21:33:45.697[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:45.698[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:45.704[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:45.712[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:45.736[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:45.737[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:45.738[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 48[0m
[32m2025-11-22 21:33:45.738[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([48, 1280])[0m
[32m2025-11-22 21:33:45.739[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[1, 6, 8]], device='cuda:2')[0m
[32m2025-11-22 21:33:45.739[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1, 12, 36]], device='cuda:2')[0m
[32m2025-11-22 21:33:45.788[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:45.798[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 12[0m
[32m2025-11-22 21:33:45.799[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 112x168 (96 patches), Resized: 112x168 (96 patches), Final APT: 12 patches[0m
[32m2025-11-22 21:33:45.801[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:45.803[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:45.805[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:45.805[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:45.806[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[1, 2, 6]]) after filter[0m
[32m2025-11-22 21:33:45.806[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 152]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 152])[0m
[32m2025-11-22 21:33:45.806[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[1, 2, 6]])[0m
[32m2025-11-22 21:33:45.806[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:45.807[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 3]), pos:tensor([[0, 0, 0],
        [0, 0, 0],
        [0, 1, 2]])[0m
[32m2025-11-22 21:33:45.809[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 152]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151]])[0m
[32m2025-11-22 21:33:45.809[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:45.809[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:45.819[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 12[0m
[32m2025-11-22 21:33:45.819[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([12, 1280])[0m
[32m2025-11-22 21:33:45.819[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[1, 2, 6]], device='cuda:3')[0m
[32m2025-11-22 21:33:45.820[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1,  8, 12]], device='cuda:3')[0m
[32m2025-11-22 21:33:45.825[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:45.828[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:45.871[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:45.881[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:45.904[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:45.905[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:46.079[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 40[0m
[32m2025-11-22 21:33:46.079[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 308x224 (352 patches), Resized: 336x224 (384 patches), Final APT: 40 patches[0m
[32m2025-11-22 21:33:46.088[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:46.092[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:46.092[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:46.092[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[ 1,  4, 10]]) after filter[0m
[32m2025-11-22 21:33:46.092[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 192]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 192])[0m
[32m2025-11-22 21:33:46.092[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[ 1,  4, 10]])[0m
[32m2025-11-22 21:33:46.093[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:46.093[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 10]), pos:tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],
        [0, 1, 2, 3, 4, 0, 1, 2, 3, 4]])[0m
[32m2025-11-22 21:33:46.096[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 192]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  20,  21,  22,
          23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,
          37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,
          51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,
          65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,
          79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,
          93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106,
         107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,
         121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134,
         135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
         149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
         163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176,
         177, 178, 179, 180, 181, 182, 183, 184, 185, 186],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  16,  16,  16,  16,  16,  20,  21,  22,
          23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,
          37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,
          51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,
          65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,
          79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,
          93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106,
         107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,
         121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134,
         135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
         149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
         163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176,
         177, 178, 179, 180, 181, 182, 183, 184, 185, 186],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  19,  15,  16,  17,  18,  19,  20,  21,  22,
          23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,
          37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,
          51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,
          65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,
          79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,
          93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106,
         107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,
         121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134,
         135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
         149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
         163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176,
         177, 178, 179, 180, 181, 182, 183, 184, 185, 186]])[0m
[32m2025-11-22 21:33:46.096[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:46.097[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:46.134[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 40[0m
[32m2025-11-22 21:33:46.134[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([40, 1280])[0m
[32m2025-11-22 21:33:46.134[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[ 1,  4, 10]], device='cuda:2')[0m
[32m2025-11-22 21:33:46.134[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1, 24, 16]], device='cuda:2')[0m
[32m2025-11-22 21:33:46.189[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:46.198[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:46.223[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:46.225[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:46.363[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 76[0m
[32m2025-11-22 21:33:46.363[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 280x504 (720 patches), Resized: 280x504 (720 patches), Final APT: 76 patches[0m
[32m2025-11-22 21:33:46.377[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:46.380[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:46.380[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:46.380[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[ 1,  2, 38]]) after filter[0m
[32m2025-11-22 21:33:46.380[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 168]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 168])[0m
[32m2025-11-22 21:33:46.380[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[ 1,  2, 38]])[0m
[32m2025-11-22 21:33:46.381[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:46.381[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 19]), pos:tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0],
        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0],
        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18]])[0m
[32m2025-11-22 21:33:46.384[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 168]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167]])[0m
[32m2025-11-22 21:33:46.384[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:46.384[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:46.447[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 76[0m
[32m2025-11-22 21:33:46.447[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([76, 1280])[0m
[32m2025-11-22 21:33:46.447[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[ 1,  2, 38]], device='cuda:3')[0m
[32m2025-11-22 21:33:46.447[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1, 20, 36]], device='cuda:3')[0m
[32m2025-11-22 21:33:46.494[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:46.497[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:46.521[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:46.522[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:46.580[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 12[0m
[32m2025-11-22 21:33:46.580[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 112x140 (80 patches), Resized: 112x168 (96 patches), Final APT: 12 patches[0m
[32m2025-11-22 21:33:46.583[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:46.586[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:46.586[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:46.587[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[1, 2, 6]]) after filter[0m
[32m2025-11-22 21:33:46.587[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 150]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 150])[0m
[32m2025-11-22 21:33:46.587[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[1, 2, 6]])[0m
[32m2025-11-22 21:33:46.587[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:46.588[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 3]), pos:tensor([[0, 0, 0],
        [0, 0, 0],
        [0, 1, 2]])[0m
[32m2025-11-22 21:33:46.590[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 150]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149]])[0m
[32m2025-11-22 21:33:46.590[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:46.590[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:46.600[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 12[0m
[32m2025-11-22 21:33:46.600[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([12, 1280])[0m
[32m2025-11-22 21:33:46.600[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[1, 2, 6]], device='cuda:3')[0m
[32m2025-11-22 21:33:46.600[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1,  8, 12]], device='cuda:3')[0m
[32m2025-11-22 21:33:46.646[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:46.651[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:46.674[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:46.675[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:46.957[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 616[0m
[32m2025-11-22 21:33:46.959[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 728x1512 (5616 patches), Resized: 728x1512 (5616 patches), Final APT: 616 patches[0m
[32m2025-11-22 21:33:47.049[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:47.111[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:47.111[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:47.258[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 424[0m
[32m2025-11-22 21:33:47.259[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 588x1288 (3864 patches), Resized: 616x1288 (4048 patches), Final APT: 424 patches[0m
[32m2025-11-22 21:33:47.318[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:47.321[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:47.321[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:47.321[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[  1,   4, 106]]) after filter[0m
[32m2025-11-22 21:33:47.321[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 357]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 357])[0m
[32m2025-11-22 21:33:47.321[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[  1,   4, 106]])[0m
[32m2025-11-22 21:33:47.322[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:47.324[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 106]), pos:tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,
          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,
          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,
          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],
        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52,  0,
          1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,
         19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,
         37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52]])[0m
[32m2025-11-22 21:33:47.324[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 357]), llm_positions:tensor([[  0,   1,   2,  ..., 301, 302, 303],
        [  0,   1,   2,  ..., 301, 302, 303],
        [  0,   1,   2,  ..., 301, 302, 303]])[0m
[32m2025-11-22 21:33:47.325[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:47.326[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:47.462[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[ 1, 22, 28]]) after filter[0m
[32m2025-11-22 21:33:47.462[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 446]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 446])[0m
[32m2025-11-22 21:33:47.462[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[ 1, 22, 28]])[0m
[32m2025-11-22 21:33:47.494[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:47.497[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 154]), pos:tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,
          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,
          2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,
          3,  3,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,  5,
          5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,
          6,  6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,
          7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,
          9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10, 10,
         10, 10, 10, 10, 10, 10, 10, 10, 10, 10],
        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,  0,  1,  2,  3,
          4,  5,  6,  7,  8,  9, 10, 11, 12, 13,  0,  1,  2,  3,  4,  5,  6,  7,
          8,  9, 10, 11, 12, 13,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11,
         12, 13,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,  0,  1,
          2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,  0,  1,  2,  3,  4,  5,
          6,  7,  8,  9, 10, 11, 12, 13,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9,
         10, 11, 12, 13,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,
          0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,  0,  1,  2,  3,
          4,  5,  6,  7,  8,  9, 10, 11, 12, 13]])[0m
[32m2025-11-22 21:33:47.498[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 446]), llm_positions:tensor([[  0,   1,   2,  ..., 303, 304, 305],
        [  0,   1,   2,  ..., 303, 304, 305],
        [  0,   1,   2,  ..., 303, 304, 305]])[0m
[32m2025-11-22 21:33:47.498[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:47.503[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:47.689[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 424[0m
[32m2025-11-22 21:33:47.690[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([424, 1280])[0m
[32m2025-11-22 21:33:47.690[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[  1,   4, 106]], device='cuda:0')[0m
[32m2025-11-22 21:33:47.690[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1, 44, 92]], device='cuda:0')[0m
[32m2025-11-22 21:33:47.747[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:47.770[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:47.801[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:47.802[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:47.868[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 268[0m
[32m2025-11-22 21:33:47.868[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 392x1232 (2464 patches), Resized: 392x1232 (2464 patches), Final APT: 268 patches[0m
[32m2025-11-22 21:33:47.908[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:47.912[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:47.912[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:47.912[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[  1,   2, 134]]) after filter[0m
[32m2025-11-22 21:33:47.912[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 245]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 245])[0m
[32m2025-11-22 21:33:47.912[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[  1,   2, 134]])[0m
[32m2025-11-22 21:33:47.913[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:47.914[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 67]), pos:tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66]])[0m
[32m2025-11-22 21:33:47.917[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 245]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,
         168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,
         182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,
         196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,
         210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,
         224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,
         238, 239, 240, 241, 242, 243, 244],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,
         168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,
         182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,
         196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,
         210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,
         224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,
         238, 239, 240, 241, 242, 243, 244],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,
         168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,
         182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,
         196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,
         210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,
         224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,
         238, 239, 240, 241, 242, 243, 244]])[0m
[32m2025-11-22 21:33:47.918[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:47.918[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:48.141[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 268[0m
[32m2025-11-22 21:33:48.142[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([268, 1280])[0m
[32m2025-11-22 21:33:48.142[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[  1,   2, 134]], device='cuda:2')[0m
[32m2025-11-22 21:33:48.143[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1, 28, 88]], device='cuda:2')[0m
[32m2025-11-22 21:33:48.200[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:48.212[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:48.222[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 616[0m
[32m2025-11-22 21:33:48.223[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([616, 1280])[0m
[32m2025-11-22 21:33:48.223[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[ 1, 22, 28]], device='cuda:1')[0m
[32m2025-11-22 21:33:48.223[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[  1,  52, 108]], device='cuda:1')[0m
[32m2025-11-22 21:33:48.236[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:48.238[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:48.427[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 112[0m
[32m2025-11-22 21:33:48.427[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 504x392 (1008 patches), Resized: 504x392 (1008 patches), Final APT: 112 patches[0m
[32m2025-11-22 21:33:48.431[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:48.444[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:48.450[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:48.450[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:48.451[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[ 1,  8, 14]]) after filter[0m
[32m2025-11-22 21:33:48.451[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 277]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 277])[0m
[32m2025-11-22 21:33:48.451[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[ 1,  8, 14]])[0m
[32m2025-11-22 21:33:48.451[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:48.452[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 28]), pos:tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3,
         3, 3, 3, 3],
        [0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2,
         3, 4, 5, 6]])[0m
[32m2025-11-22 21:33:48.456[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 277]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,
          35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,
          49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,
          63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,
          77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,
          91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,
         105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,
         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132,
         133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
         147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
         161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174,
         175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188,
         189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202,
         203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216,
         217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,
         231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244,
         245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  16,  16,  16,  16,  16,  16,
          16,  17,  17,  17,  17,  17,  17,  17,  18,  18,  18,  18,  18,  18,
          18,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,
          35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,
          49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,
          63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,
          77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,
          91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,
         105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,
         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132,
         133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
         147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
         161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174,
         175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188,
         189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202,
         203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216,
         217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,
         231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244,
         245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  19,  20,  21,  15,  16,  17,  18,  19,  20,
          21,  15,  16,  17,  18,  19,  20,  21,  15,  16,  17,  18,  19,  20,
          21,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,
          35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,
          49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,
          63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,
          77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,
          91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,
         105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,
         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132,
         133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
         147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
         161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174,
         175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188,
         189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202,
         203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216,
         217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,
         231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244,
         245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255]])[0m
[32m2025-11-22 21:33:48.456[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:48.456[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:48.460[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:48.506[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:48.507[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:48.545[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 112[0m
[32m2025-11-22 21:33:48.546[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([112, 1280])[0m
[32m2025-11-22 21:33:48.546[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[ 1,  8, 14]], device='cuda:0')[0m
[32m2025-11-22 21:33:48.546[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1, 36, 28]], device='cuda:0')[0m
[32m2025-11-22 21:33:48.599[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:48.620[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:48.644[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:48.646[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:48.790[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 40[0m
[32m2025-11-22 21:33:48.791[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 308x252 (396 patches), Resized: 336x280 (480 patches), Final APT: 40 patches[0m
[32m2025-11-22 21:33:48.802[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:48.805[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:48.805[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:48.806[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[ 1,  4, 10]]) after filter[0m
[32m2025-11-22 21:33:48.806[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 277]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 277])[0m
[32m2025-11-22 21:33:48.806[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[ 1,  4, 10]])[0m
[32m2025-11-22 21:33:48.806[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:48.807[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 10]), pos:tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],
        [0, 1, 2, 3, 4, 0, 1, 2, 3, 4]])[0m
[32m2025-11-22 21:33:48.811[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 277]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  20,  21,  22,
          23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,
          37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,
          51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,
          65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,
          79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,
          93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106,
         107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,
         121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134,
         135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
         149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
         163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176,
         177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190,
         191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204,
         205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218,
         219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232,
         233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,
         247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260,
         261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  16,  16,  16,  16,  16,  20,  21,  22,
          23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,
          37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,
          51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,
          65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,
          79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,
          93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106,
         107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,
         121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134,
         135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
         149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
         163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176,
         177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190,
         191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204,
         205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218,
         219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232,
         233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,
         247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260,
         261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  19,  15,  16,  17,  18,  19,  20,  21,  22,
          23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,
          37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,
          51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,
          65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,
          79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,
          93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106,
         107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,
         121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134,
         135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
         149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
         163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176,
         177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190,
         191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204,
         205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218,
         219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232,
         233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,
         247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260,
         261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271]])[0m
[32m2025-11-22 21:33:48.812[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:48.812[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:48.856[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 40[0m
[32m2025-11-22 21:33:48.857[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([40, 1280])[0m
[32m2025-11-22 21:33:48.857[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[ 1,  4, 10]], device='cuda:1')[0m
[32m2025-11-22 21:33:48.857[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1, 24, 20]], device='cuda:1')[0m
[32m2025-11-22 21:33:48.914[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:48.937[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:48.955[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 120[0m
[32m2025-11-22 21:33:48.955[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 392x560 (1120 patches), Resized: 392x560 (1120 patches), Final APT: 120 patches[0m
[32m2025-11-22 21:33:48.961[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:48.962[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:48.975[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:48.981[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:48.981[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:48.981[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[ 1, 10, 12]]) after filter[0m
[32m2025-11-22 21:33:48.981[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 203]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 203])[0m
[32m2025-11-22 21:33:48.981[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[ 1, 10, 12]])[0m
[32m2025-11-22 21:33:48.983[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:48.983[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 30]), pos:tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,
         4, 4, 4, 4, 4, 4],
        [0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5,
         0, 1, 2, 3, 4, 5]])[0m
[32m2025-11-22 21:33:48.986[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 203]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  21,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,
          32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,
          46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,
          60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,
          74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,
          88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101,
         102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115,
         116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,
         130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,
         144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
         158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,
         172, 173, 174, 175, 176, 177, 178],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  16,  16,  16,  16,  16,  16,  17,
          17,  17,  17,  17,  17,  18,  18,  18,  18,  18,  18,  19,  19,  19,
          19,  19,  19,  21,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,
          32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,
          46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,
          60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,
          74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,
          88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101,
         102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115,
         116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,
         130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,
         144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
         158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,
         172, 173, 174, 175, 176, 177, 178],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  19,  20,  15,  16,  17,  18,  19,  20,  15,
          16,  17,  18,  19,  20,  15,  16,  17,  18,  19,  20,  15,  16,  17,
          18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,
          32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,
          46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,
          60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,
          74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,
          88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101,
         102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115,
         116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,
         130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,
         144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
         158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,
         172, 173, 174, 175, 176, 177, 178]])[0m
[32m2025-11-22 21:33:48.987[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:48.987[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:49.087[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 120[0m
[32m2025-11-22 21:33:49.087[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([120, 1280])[0m
[32m2025-11-22 21:33:49.088[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[ 1, 10, 12]], device='cuda:2')[0m
[32m2025-11-22 21:33:49.088[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1, 28, 40]], device='cuda:2')[0m
[32m2025-11-22 21:33:49.093[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 416[0m
[32m2025-11-22 21:33:49.093[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 616x1204 (3784 patches), Resized: 616x1232 (3872 patches), Final APT: 416 patches[0m
[32m2025-11-22 21:33:49.141[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:49.149[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:49.152[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:49.152[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:49.153[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[ 1, 16, 26]]) after filter[0m
[32m2025-11-22 21:33:49.153[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 250]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 250])[0m
[32m2025-11-22 21:33:49.153[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[ 1, 16, 26]])[0m
[32m2025-11-22 21:33:49.156[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:49.157[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:49.158[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 104]), pos:tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,
          1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,
          2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,
          4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  5,  5,  5,
          5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,
          6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7],
        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12,  0,  1,  2,  3,  4,
          5,  6,  7,  8,  9, 10, 11, 12,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9,
         10, 11, 12,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12,  0,  1,
          2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12,  0,  1,  2,  3,  4,  5,  6,
          7,  8,  9, 10, 11, 12,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11,
         12,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12]])[0m
[32m2025-11-22 21:33:49.161[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 250]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  15,  28,  29,  30,  31,  32,  33,  34,
          35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,
          49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,
          63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,
          77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,
          91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,
         105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,
         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132,
         133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
         147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  17,
          17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  18,  18,
          18,  18,  18,  18,  18,  18,  18,  18,  18,  18,  18,  19,  19,  19,
          19,  19,  19,  19,  19,  19,  19,  19,  19,  19,  20,  20,  20,  20,
          20,  20,  20,  20,  20,  20,  20,  20,  20,  21,  21,  21,  21,  21,
          21,  21,  21,  21,  21,  21,  21,  21,  22,  22,  22,  22,  22,  22,
          22,  22,  22,  22,  22,  22,  22,  28,  29,  30,  31,  32,  33,  34,
          35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,
          49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,
          63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,
          77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,
          91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,
         105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,
         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132,
         133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
         147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  15,
          16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  15,  16,
          17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  15,  16,  17,
          18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  15,  16,  17,  18,
          19,  20,  21,  22,  23,  24,  25,  26,  27,  15,  16,  17,  18,  19,
          20,  21,  22,  23,  24,  25,  26,  27,  15,  16,  17,  18,  19,  20,
          21,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,
          35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,
          49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,
          63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,
          77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,
          91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,
         105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,
         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132,
         133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
         147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158]])[0m
[32m2025-11-22 21:33:49.162[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:49.162[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:49.181[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:49.184[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:49.322[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 112[0m
[32m2025-11-22 21:33:49.322[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 644x308 (1012 patches), Resized: 672x336 (1152 patches), Final APT: 112 patches[0m
[32m2025-11-22 21:33:49.330[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 60[0m
[32m2025-11-22 21:33:49.330[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 196x532 (532 patches), Resized: 224x560 (640 patches), Final APT: 60 patches[0m
[32m2025-11-22 21:33:49.343[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:49.344[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:49.346[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:49.346[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:49.346[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[ 1,  8, 14]]) after filter[0m
[32m2025-11-22 21:33:49.346[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 270]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 270])[0m
[32m2025-11-22 21:33:49.346[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[ 1,  8, 14]])[0m
[32m2025-11-22 21:33:49.347[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:49.347[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:49.347[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[ 1,  6, 10]]) after filter[0m
[32m2025-11-22 21:33:49.347[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 252]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 252])[0m
[32m2025-11-22 21:33:49.347[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:49.347[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[ 1,  6, 10]])[0m
[32m2025-11-22 21:33:49.348[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:49.348[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 28]), pos:tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3,
         3, 3, 3, 3],
        [0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2,
         3, 4, 5, 6]])[0m
[32m2025-11-22 21:33:49.348[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 15]), pos:tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2],
        [0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4]])[0m
[32m2025-11-22 21:33:49.351[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 270]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,
          35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,
          49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,
          63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,
          77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,
          91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,
         105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,
         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132,
         133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
         147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
         161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174,
         175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188,
         189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202,
         203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216,
         217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,
         231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244,
         245, 246, 247, 248],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  16,  16,  16,  16,  16,  16,
          16,  17,  17,  17,  17,  17,  17,  17,  18,  18,  18,  18,  18,  18,
          18,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,
          35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,
          49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,
          63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,
          77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,
          91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,
         105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,
         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132,
         133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
         147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
         161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174,
         175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188,
         189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202,
         203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216,
         217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,
         231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244,
         245, 246, 247, 248],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  19,  20,  21,  15,  16,  17,  18,  19,  20,
          21,  15,  16,  17,  18,  19,  20,  21,  15,  16,  17,  18,  19,  20,
          21,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,
          35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,
          49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,
          63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,
          77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,
          91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,
         105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,
         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132,
         133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
         147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
         161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174,
         175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188,
         189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202,
         203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216,
         217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,
         231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244,
         245, 246, 247, 248]])[0m
[32m2025-11-22 21:33:49.351[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 252]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,
          32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,
          46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,
          60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,
          74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,
          88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101,
         102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115,
         116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,
         130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,
         144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
         158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,
         172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185,
         186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199,
         200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213,
         214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227,
         228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  16,  16,  16,  16,  16,  17,  17,  17,
          17,  17,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,
          32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,
          46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,
          60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,
          74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,
          88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101,
         102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115,
         116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,
         130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,
         144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
         158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,
         172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185,
         186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199,
         200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213,
         214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227,
         228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  19,  15,  16,  17,  18,  19,  15,  16,  17,
          18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,
          32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,
          46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,
          60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,
          74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,
          88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101,
         102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115,
         116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,
         130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,
         144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
         158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,
         172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185,
         186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199,
         200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213,
         214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227,
         228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241]])[0m
[32m2025-11-22 21:33:49.351[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:49.352[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:49.352[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:49.352[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:49.412[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 60[0m
[32m2025-11-22 21:33:49.412[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([60, 1280])[0m
[32m2025-11-22 21:33:49.412[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[ 1,  6, 10]], device='cuda:1')[0m
[32m2025-11-22 21:33:49.412[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1, 16, 40]], device='cuda:1')[0m
[32m2025-11-22 21:33:49.454[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 112[0m
[32m2025-11-22 21:33:49.454[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([112, 1280])[0m
[32m2025-11-22 21:33:49.454[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[ 1,  8, 14]], device='cuda:0')[0m
[32m2025-11-22 21:33:49.455[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1, 48, 24]], device='cuda:0')[0m
[32m2025-11-22 21:33:49.462[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:49.473[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:49.498[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:49.499[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:49.504[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:49.509[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 416[0m
[32m2025-11-22 21:33:49.510[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([416, 1280])[0m
[32m2025-11-22 21:33:49.510[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[ 1, 16, 26]], device='cuda:3')[0m
[32m2025-11-22 21:33:49.510[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1, 44, 88]], device='cuda:3')[0m
[32m2025-11-22 21:33:49.527[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:49.550[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:49.551[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:49.562[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:49.574[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:49.597[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:49.598[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:49.632[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 8[0m
[32m2025-11-22 21:33:49.632[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 112x112 (64 patches), Resized: 112x112 (64 patches), Final APT: 8 patches[0m
[32m2025-11-22 21:33:49.635[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:49.638[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:49.638[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:49.638[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[1, 2, 4]]) after filter[0m
[32m2025-11-22 21:33:49.638[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 146]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 146])[0m
[32m2025-11-22 21:33:49.638[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[1, 2, 4]])[0m
[32m2025-11-22 21:33:49.641[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:49.641[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 2]), pos:tensor([[0, 0],
        [0, 0],
        [0, 1]])[0m
[32m2025-11-22 21:33:49.643[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 146]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145]])[0m
[32m2025-11-22 21:33:49.644[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:49.644[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:49.651[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 8[0m
[32m2025-11-22 21:33:49.651[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([8, 1280])[0m
[32m2025-11-22 21:33:49.651[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[1, 2, 4]], device='cuda:3')[0m
[32m2025-11-22 21:33:49.652[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[1, 8, 8]], device='cuda:3')[0m
[32m2025-11-22 21:33:49.665[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 28[0m
[32m2025-11-22 21:33:49.665[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 224x224 (256 patches), Resized: 224x224 (256 patches), Final APT: 28 patches[0m
[32m2025-11-22 21:33:49.672[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:49.677[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:49.677[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:49.677[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[ 1,  2, 14]]) after filter[0m
[32m2025-11-22 21:33:49.677[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 231]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 231])[0m
[32m2025-11-22 21:33:49.677[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[ 1,  2, 14]])[0m
[32m2025-11-22 21:33:49.678[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:49.678[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 7]), pos:tensor([[0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0],
        [0, 1, 2, 3, 4, 5, 6]])[0m
[32m2025-11-22 21:33:49.681[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 231]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,
         168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,
         182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,
         196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,
         210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,
         224, 225, 226, 227, 228, 229, 230],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,
         168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,
         182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,
         196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,
         210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,
         224, 225, 226, 227, 228, 229, 230],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,
         168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,
         182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,
         196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,
         210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,
         224, 225, 226, 227, 228, 229, 230]])[0m
[32m2025-11-22 21:33:49.682[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:49.682[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:49.683[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 84[0m
[32m2025-11-22 21:33:49.683[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 308x476 (748 patches), Resized: 336x504 (864 patches), Final APT: 84 patches[0m
[32m2025-11-22 21:33:49.699[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:49.701[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:49.702[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:49.703[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:49.703[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[ 1,  6, 14]]) after filter[0m
[32m2025-11-22 21:33:49.703[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 188]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 188])[0m
[32m2025-11-22 21:33:49.703[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[ 1,  6, 14]])[0m
[32m2025-11-22 21:33:49.703[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:49.704[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 21]), pos:tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2],
        [0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6]])[0m
[32m2025-11-22 21:33:49.705[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 28[0m
[32m2025-11-22 21:33:49.705[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([28, 1280])[0m
[32m2025-11-22 21:33:49.706[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[ 1,  2, 14]], device='cuda:1')[0m
[32m2025-11-22 21:33:49.706[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1, 16, 16]], device='cuda:1')[0m
[32m2025-11-22 21:33:49.707[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 188]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  15,  15,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,
         168, 169, 170, 171, 172, 173],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  16,  16,  16,  16,  16,  16,
          16,  17,  17,  17,  17,  17,  17,  17,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,
         168, 169, 170, 171, 172, 173],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  19,  20,  21,  15,  16,  17,  18,  19,  20,
          21,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,
         168, 169, 170, 171, 172, 173]])[0m
[32m2025-11-22 21:33:49.707[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:49.708[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:49.711[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:49.734[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:49.735[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:49.765[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:49.775[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:49.785[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 84[0m
[32m2025-11-22 21:33:49.786[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([84, 1280])[0m
[32m2025-11-22 21:33:49.786[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[ 1,  6, 14]], device='cuda:2')[0m
[32m2025-11-22 21:33:49.786[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1, 24, 36]], device='cuda:2')[0m
[32m2025-11-22 21:33:49.800[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:49.801[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:49.835[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:49.838[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:49.855[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 24[0m
[32m2025-11-22 21:33:49.855[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 112x336 (192 patches), Resized: 112x336 (192 patches), Final APT: 24 patches[0m
[32m2025-11-22 21:33:49.860[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:49.862[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:49.862[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:49.862[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:49.863[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[1, 4, 6]]) after filter[0m
[32m2025-11-22 21:33:49.863[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 148]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 148])[0m
[32m2025-11-22 21:33:49.863[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[1, 4, 6]])[0m
[32m2025-11-22 21:33:49.863[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:49.864[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:49.864[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 6]), pos:tensor([[0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 1, 1],
        [0, 1, 2, 0, 1, 2]])[0m
[32m2025-11-22 21:33:49.866[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 148]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  18,  19,  20,  21,  22,  23,  24,
          25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,
          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,
          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,
          67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,
          81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,
          95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108,
         109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122,
         123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136,
         137, 138, 139, 140, 141, 142, 143, 144],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  16,  16,  16,  18,  19,  20,  21,  22,  23,  24,
          25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,
          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,
          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,
          67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,
          81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,
          95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108,
         109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122,
         123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136,
         137, 138, 139, 140, 141, 142, 143, 144],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,
          25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,
          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,
          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,
          67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,
          81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,
          95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108,
         109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122,
         123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136,
         137, 138, 139, 140, 141, 142, 143, 144]])[0m
[32m2025-11-22 21:33:49.866[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:49.867[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:49.885[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 24[0m
[32m2025-11-22 21:33:49.885[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([24, 1280])[0m
[32m2025-11-22 21:33:49.885[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[1, 4, 6]], device='cuda:3')[0m
[32m2025-11-22 21:33:49.886[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1,  8, 24]], device='cuda:3')[0m
[32m2025-11-22 21:33:49.936[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:49.947[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:49.970[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:49.971[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:50.420[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 76[0m
[32m2025-11-22 21:33:50.420[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 280x504 (720 patches), Resized: 280x504 (720 patches), Final APT: 76 patches[0m
[32m2025-11-22 21:33:50.433[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:50.436[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:50.436[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:50.436[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[ 1,  2, 38]]) after filter[0m
[32m2025-11-22 21:33:50.436[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 161]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 161])[0m
[32m2025-11-22 21:33:50.436[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[ 1,  2, 38]])[0m
[32m2025-11-22 21:33:50.437[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:50.438[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 19]), pos:tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0],
        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0],
        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18]])[0m
[32m2025-11-22 21:33:50.440[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 161]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159, 160],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159, 160],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159, 160]])[0m
[32m2025-11-22 21:33:50.440[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:50.440[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:50.504[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 76[0m
[32m2025-11-22 21:33:50.504[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([76, 1280])[0m
[32m2025-11-22 21:33:50.504[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[ 1,  2, 38]], device='cuda:3')[0m
[32m2025-11-22 21:33:50.504[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1, 20, 36]], device='cuda:3')[0m
[32m2025-11-22 21:33:50.527[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 108[0m
[32m2025-11-22 21:33:50.527[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 280x700 (1000 patches), Resized: 280x728 (1040 patches), Final APT: 108 patches[0m
[32m2025-11-22 21:33:50.546[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:50.550[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:50.550[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:50.550[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:50.551[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[ 1,  6, 18]]) after filter[0m
[32m2025-11-22 21:33:50.551[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 188]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 188])[0m
[32m2025-11-22 21:33:50.551[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[ 1,  6, 18]])[0m
[32m2025-11-22 21:33:50.551[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:50.552[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 27]), pos:tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2,
         2, 2, 2],
        [0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 1, 2, 3, 4, 5,
         6, 7, 8]])[0m
[32m2025-11-22 21:33:50.553[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:50.555[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 188]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,
          38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,
          52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,
          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,
          80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,
          94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,
         108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,
         122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135,
         136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
         150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,
         164, 165, 166, 167, 168, 169],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  15,  15,  16,  16,  16,  16,
          16,  16,  16,  16,  16,  17,  17,  17,  17,  17,  17,  17,  17,  17,
          24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,
          38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,
          52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,
          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,
          80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,
          94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,
         108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,
         122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135,
         136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
         150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,
         164, 165, 166, 167, 168, 169],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  15,  16,  17,  18,
          19,  20,  21,  22,  23,  15,  16,  17,  18,  19,  20,  21,  22,  23,
          24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,
          38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,
          52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,
          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,
          80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,
          94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,
         108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,
         122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135,
         136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
         150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,
         164, 165, 166, 167, 168, 169]])[0m
[32m2025-11-22 21:33:50.555[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:50.555[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:50.577[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:50.577[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:50.646[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 108[0m
[32m2025-11-22 21:33:50.646[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([108, 1280])[0m
[32m2025-11-22 21:33:50.646[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[ 1,  6, 18]], device='cuda:2')[0m
[32m2025-11-22 21:33:50.647[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1, 20, 52]], device='cuda:2')[0m
[32m2025-11-22 21:33:50.650[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 132[0m
[32m2025-11-22 21:33:50.651[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 252x952 (1224 patches), Resized: 280x952 (1360 patches), Final APT: 132 patches[0m
[32m2025-11-22 21:33:50.673[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:50.676[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:50.676[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:50.676[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[ 1,  6, 22]]) after filter[0m
[32m2025-11-22 21:33:50.676[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 256]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 256])[0m
[32m2025-11-22 21:33:50.676[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[ 1,  6, 22]])[0m
[32m2025-11-22 21:33:50.677[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:50.678[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 33]), pos:tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,
          1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2],
        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10,  0,  1,  2,  3,  4,  5,  6,
          7,  8,  9, 10,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]])[0m
[32m2025-11-22 21:33:50.681[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 256]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  26,  27,  28,  29,  30,  31,  32,  33,
          34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,
          48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,
          62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,
          76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,
          90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,
         104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,
         118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,
         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
         146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
         160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173,
         174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187,
         188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201,
         202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215,
         216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229,
         230, 231, 232, 233],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  16,  16,
          16,  16,  16,  16,  16,  16,  16,  16,  16,  17,  17,  17,  17,  17,
          17,  17,  17,  17,  17,  17,  26,  27,  28,  29,  30,  31,  32,  33,
          34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,
          48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,
          62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,
          76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,
          90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,
         104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,
         118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,
         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
         146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
         160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173,
         174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187,
         188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201,
         202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215,
         216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229,
         230, 231, 232, 233],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  15,  16,
          17,  18,  19,  20,  21,  22,  23,  24,  25,  15,  16,  17,  18,  19,
          20,  21,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,
          34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,
          48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,
          62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,
          76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,
          90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,
         104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,
         118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,
         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
         146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
         160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173,
         174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187,
         188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201,
         202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215,
         216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229,
         230, 231, 232, 233]])[0m
[32m2025-11-22 21:33:50.681[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:50.681[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:50.694[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:50.697[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:50.721[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:50.722[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:50.789[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 12[0m
[32m2025-11-22 21:33:50.790[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 112x140 (80 patches), Resized: 112x168 (96 patches), Final APT: 12 patches[0m
[32m2025-11-22 21:33:50.796[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:50.799[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:50.800[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:50.800[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[1, 2, 6]]) after filter[0m
[32m2025-11-22 21:33:50.800[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 161]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 161])[0m
[32m2025-11-22 21:33:50.800[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[1, 2, 6]])[0m
[32m2025-11-22 21:33:50.801[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:50.801[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 3]), pos:tensor([[0, 0, 0],
        [0, 0, 0],
        [0, 1, 2]])[0m
[32m2025-11-22 21:33:50.803[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 161]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159, 160],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159, 160],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159, 160]])[0m
[32m2025-11-22 21:33:50.804[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:50.804[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:50.813[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 132[0m
[32m2025-11-22 21:33:50.813[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([132, 1280])[0m
[32m2025-11-22 21:33:50.813[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[ 1,  6, 22]], device='cuda:1')[0m
[32m2025-11-22 21:33:50.813[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1, 20, 68]], device='cuda:1')[0m
[32m2025-11-22 21:33:50.814[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 12[0m
[32m2025-11-22 21:33:50.814[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([12, 1280])[0m
[32m2025-11-22 21:33:50.814[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[1, 2, 6]], device='cuda:2')[0m
[32m2025-11-22 21:33:50.814[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1,  8, 12]], device='cuda:2')[0m
[32m2025-11-22 21:33:50.864[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:50.865[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:50.872[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:50.873[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:50.896[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:50.897[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:50.897[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:50.898[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:51.072[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 24[0m
[32m2025-11-22 21:33:51.072[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 336x140 (240 patches), Resized: 336x168 (288 patches), Final APT: 24 patches[0m
[32m2025-11-22 21:33:51.079[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:51.082[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:51.082[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:51.082[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[1, 4, 6]]) after filter[0m
[32m2025-11-22 21:33:51.082[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 164]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 164])[0m
[32m2025-11-22 21:33:51.083[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[1, 4, 6]])[0m
[32m2025-11-22 21:33:51.083[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:51.084[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 6]), pos:tensor([[0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 1, 1],
        [0, 1, 2, 0, 1, 2]])[0m
[32m2025-11-22 21:33:51.086[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 164]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  18,  19,  20,  21,  22,  23,  24,
          25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,
          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,
          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,
          67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,
          81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,
          95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108,
         109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122,
         123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136,
         137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
         151, 152, 153, 154, 155, 156, 157, 158, 159, 160],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  16,  16,  16,  18,  19,  20,  21,  22,  23,  24,
          25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,
          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,
          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,
          67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,
          81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,
          95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108,
         109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122,
         123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136,
         137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
         151, 152, 153, 154, 155, 156, 157, 158, 159, 160],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,
          25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,
          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,
          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,
          67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,
          81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,
          95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108,
         109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122,
         123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136,
         137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
         151, 152, 153, 154, 155, 156, 157, 158, 159, 160]])[0m
[32m2025-11-22 21:33:51.086[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:51.087[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:51.113[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 24[0m
[32m2025-11-22 21:33:51.113[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([24, 1280])[0m
[32m2025-11-22 21:33:51.114[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[1, 4, 6]], device='cuda:2')[0m
[32m2025-11-22 21:33:51.114[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1, 24, 12]], device='cuda:2')[0m
[32m2025-11-22 21:33:51.164[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:51.167[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:51.191[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:51.192[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:51.276[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 12[0m
[32m2025-11-22 21:33:51.276[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 140x168 (120 patches), Resized: 168x168 (144 patches), Final APT: 12 patches[0m
[32m2025-11-22 21:33:51.282[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:51.284[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:51.284[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:51.285[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[1, 2, 6]]) after filter[0m
[32m2025-11-22 21:33:51.285[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 159]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 159])[0m
[32m2025-11-22 21:33:51.285[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[1, 2, 6]])[0m
[32m2025-11-22 21:33:51.285[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:51.286[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 3]), pos:tensor([[0, 0, 0],
        [0, 0, 0],
        [0, 1, 2]])[0m
[32m2025-11-22 21:33:51.288[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 159]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158]])[0m
[32m2025-11-22 21:33:51.288[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:51.288[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:51.302[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 12[0m
[32m2025-11-22 21:33:51.302[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([12, 1280])[0m
[32m2025-11-22 21:33:51.302[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[1, 2, 6]], device='cuda:2')[0m
[32m2025-11-22 21:33:51.303[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1, 12, 12]], device='cuda:2')[0m
[32m2025-11-22 21:33:51.349[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:51.353[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:51.377[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:51.378[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:51.530[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 100[0m
[32m2025-11-22 21:33:51.530[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 308x588 (924 patches), Resized: 336x616 (1056 patches), Final APT: 100 patches[0m
[32m2025-11-22 21:33:51.548[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:51.552[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:51.552[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:51.552[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[ 1, 10, 10]]) after filter[0m
[32m2025-11-22 21:33:51.552[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 237]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 237])[0m
[32m2025-11-22 21:33:51.553[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[ 1, 10, 10]])[0m
[32m2025-11-22 21:33:51.555[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:51.556[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 25]), pos:tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0],
        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4,
         4],
        [0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3,
         4]])[0m
[32m2025-11-22 21:33:51.559[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 237]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  20,  21,
          22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,
          36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,
          50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,
          64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,
          78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,
          92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,
         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,
         120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,
         134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
         148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
         162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,
         176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189,
         190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203,
         204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  16,  16,  16,  16,  16,  17,  17,  17,
          17,  17,  18,  18,  18,  18,  18,  19,  19,  19,  19,  19,  20,  21,
          22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,
          36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,
          50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,
          64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,
          78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,
          92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,
         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,
         120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,
         134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
         148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
         162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,
         176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189,
         190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203,
         204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  19,  15,  16,  17,  18,  19,  15,  16,  17,
          18,  19,  15,  16,  17,  18,  19,  15,  16,  17,  18,  19,  20,  21,
          22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,
          36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,
          50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,
          64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,
          78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,
          92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,
         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,
         120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,
         134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
         148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
         162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,
         176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189,
         190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203,
         204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216]])[0m
[32m2025-11-22 21:33:51.560[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:51.560[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:51.655[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 100[0m
[32m2025-11-22 21:33:51.655[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([100, 1280])[0m
[32m2025-11-22 21:33:51.655[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[ 1, 10, 10]], device='cuda:1')[0m
[32m2025-11-22 21:33:51.656[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1, 24, 44]], device='cuda:1')[0m
[32m2025-11-22 21:33:51.708[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:51.720[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:51.745[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:51.746[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:51.822[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 80[0m
[32m2025-11-22 21:33:51.823[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 280x504 (720 patches), Resized: 280x504 (720 patches), Final APT: 80 patches[0m
[32m2025-11-22 21:33:51.837[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:51.839[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:51.840[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:51.840[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[ 1,  8, 10]]) after filter[0m
[32m2025-11-22 21:33:51.840[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 175]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 175])[0m
[32m2025-11-22 21:33:51.840[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[ 1,  8, 10]])[0m
[32m2025-11-22 21:33:51.841[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:51.841[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 20]), pos:tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4]])[0m
[32m2025-11-22 21:33:51.844[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 175]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  15,  20,  21,  22,  23,  24,  25,  26,
          27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,
          41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,
          55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,
          69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,
          83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,
          97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110,
         111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124,
         125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138,
         139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
         153, 154, 155, 156, 157, 158, 159],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  16,  16,  16,  16,  16,  17,  17,  17,
          17,  17,  18,  18,  18,  18,  18,  20,  21,  22,  23,  24,  25,  26,
          27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,
          41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,
          55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,
          69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,
          83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,
          97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110,
         111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124,
         125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138,
         139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
         153, 154, 155, 156, 157, 158, 159],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  19,  15,  16,  17,  18,  19,  15,  16,  17,
          18,  19,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,
          27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,
          41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,
          55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,
          69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,
          83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,
          97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110,
         111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124,
         125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138,
         139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
         153, 154, 155, 156, 157, 158, 159]])[0m
[32m2025-11-22 21:33:51.844[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:51.844[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:51.909[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 80[0m
[32m2025-11-22 21:33:51.910[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([80, 1280])[0m
[32m2025-11-22 21:33:51.910[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[ 1,  8, 10]], device='cuda:2')[0m
[32m2025-11-22 21:33:51.911[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1, 20, 36]], device='cuda:2')[0m
[32m2025-11-22 21:33:51.961[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:51.977[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:51.989[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 40[0m
[32m2025-11-22 21:33:51.990[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 280x252 (360 patches), Resized: 280x280 (400 patches), Final APT: 40 patches[0m
[32m2025-11-22 21:33:51.998[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:52.001[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:52.002[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:52.002[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:52.002[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[ 1,  4, 10]]) after filter[0m
[32m2025-11-22 21:33:52.002[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 202]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 202])[0m
[32m2025-11-22 21:33:52.002[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:52.002[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[ 1,  4, 10]])[0m
[32m2025-11-22 21:33:52.003[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:52.003[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 10]), pos:tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],
        [0, 1, 2, 3, 4, 0, 1, 2, 3, 4]])[0m
[32m2025-11-22 21:33:52.006[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 202]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  20,  21,  22,
          23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,
          37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,
          51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,
          65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,
          79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,
          93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106,
         107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,
         121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134,
         135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
         149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
         163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176,
         177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190,
         191, 192, 193, 194, 195, 196],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  16,  16,  16,  16,  16,  20,  21,  22,
          23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,
          37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,
          51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,
          65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,
          79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,
          93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106,
         107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,
         121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134,
         135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
         149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
         163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176,
         177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190,
         191, 192, 193, 194, 195, 196],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  19,  15,  16,  17,  18,  19,  20,  21,  22,
          23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,
          37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,
          51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,
          65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,
          79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,
          93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106,
         107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,
         121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134,
         135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
         149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
         163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176,
         177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190,
         191, 192, 193, 194, 195, 196]])[0m
[32m2025-11-22 21:33:52.007[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:52.007[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:52.046[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 40[0m
[32m2025-11-22 21:33:52.046[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([40, 1280])[0m
[32m2025-11-22 21:33:52.046[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[ 1,  4, 10]], device='cuda:1')[0m
[32m2025-11-22 21:33:52.046[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1, 20, 20]], device='cuda:1')[0m
[32m2025-11-22 21:33:52.071[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 12[0m
[32m2025-11-22 21:33:52.071[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 112x168 (96 patches), Resized: 112x168 (96 patches), Final APT: 12 patches[0m
[32m2025-11-22 21:33:52.076[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:52.081[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:52.081[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:52.081[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[1, 2, 6]]) after filter[0m
[32m2025-11-22 21:33:52.081[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 156]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 156])[0m
[32m2025-11-22 21:33:52.081[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[1, 2, 6]])[0m
[32m2025-11-22 21:33:52.082[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:52.082[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 3]), pos:tensor([[0, 0, 0],
        [0, 0, 0],
        [0, 1, 2]])[0m
[32m2025-11-22 21:33:52.084[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 156]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155]])[0m
[32m2025-11-22 21:33:52.085[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:52.085[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:52.095[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 12[0m
[32m2025-11-22 21:33:52.095[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([12, 1280])[0m
[32m2025-11-22 21:33:52.095[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[1, 2, 6]], device='cuda:2')[0m
[32m2025-11-22 21:33:52.096[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1,  8, 12]], device='cuda:2')[0m
[32m2025-11-22 21:33:52.096[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:52.109[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:52.134[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:52.134[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:52.149[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:52.161[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:52.166[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 464[0m
[32m2025-11-22 21:33:52.166[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 896x924 (4224 patches), Resized: 896x952 (4352 patches), Final APT: 464 patches[0m
[32m2025-11-22 21:33:52.185[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:52.186[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:52.228[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:52.232[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:52.232[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:52.232[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[ 1,  8, 58]]) after filter[0m
[32m2025-11-22 21:33:52.232[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 343]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 343])[0m
[32m2025-11-22 21:33:52.232[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[ 1,  8, 58]])[0m
[32m2025-11-22 21:33:52.233[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:52.235[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 116]), pos:tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,
          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,
          1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,
          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  3,  3,  3,
          3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,
          3,  3,  3,  3,  3,  3,  3,  3],
        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28,  0,  1,  2,  3,  4,  5,  6,
          7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,
         25, 26, 27, 28,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,
         14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28,  0,  1,  2,
          3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,
         21, 22, 23, 24, 25, 26, 27, 28]])[0m
[32m2025-11-22 21:33:52.235[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 343]), llm_positions:tensor([[  0,   1,   2,  ..., 253, 254, 255],
        [  0,   1,   2,  ..., 253, 254, 255],
        [  0,   1,   2,  ..., 253, 254, 255]])[0m
[32m2025-11-22 21:33:52.235[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:52.235[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 16[0m
[32m2025-11-22 21:33:52.236[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:52.236[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 56x532 (152 patches), Resized: 56x560 (160 patches), Final APT: 16 patches[0m
[32m2025-11-22 21:33:52.241[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:52.244[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:52.244[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:52.244[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[1, 4, 4]]) after filter[0m
[32m2025-11-22 21:33:52.244[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 192]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 192])[0m
[32m2025-11-22 21:33:52.244[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[1, 4, 4]])[0m
[32m2025-11-22 21:33:52.245[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:52.245[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 4]), pos:tensor([[0, 0, 0, 0],
        [0, 0, 1, 1],
        [0, 1, 0, 1]])[0m
[32m2025-11-22 21:33:52.248[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 192]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  17,  18,  19,  20,  21,  22,  23,  24,  25,
          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,
          40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,
          54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,
          68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,
          82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,
          96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,
         110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,
         124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137,
         138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
         152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,
         166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179,
         180, 181, 182, 183, 184, 185, 186, 187, 188, 189],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  16,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,
          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,
          40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,
          54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,
          68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,
          82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,
          96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,
         110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,
         124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137,
         138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
         152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,
         166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179,
         180, 181, 182, 183, 184, 185, 186, 187, 188, 189],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,
          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,
          40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,
          54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,
          68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,
          82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,
          96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,
         110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,
         124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137,
         138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
         152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,
         166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179,
         180, 181, 182, 183, 184, 185, 186, 187, 188, 189]])[0m
[32m2025-11-22 21:33:52.250[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:52.251[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:52.263[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 12[0m
[32m2025-11-22 21:33:52.263[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 112x196 (112 patches), Resized: 112x224 (128 patches), Final APT: 12 patches[0m
[32m2025-11-22 21:33:52.266[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 16[0m
[32m2025-11-22 21:33:52.266[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([16, 1280])[0m
[32m2025-11-22 21:33:52.266[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[1, 4, 4]], device='cuda:1')[0m
[32m2025-11-22 21:33:52.267[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1,  4, 40]], device='cuda:1')[0m
[32m2025-11-22 21:33:52.268[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:52.270[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:52.270[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:52.270[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[1, 2, 6]]) after filter[0m
[32m2025-11-22 21:33:52.271[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 153]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 153])[0m
[32m2025-11-22 21:33:52.271[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[1, 2, 6]])[0m
[32m2025-11-22 21:33:52.271[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:52.272[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 3]), pos:tensor([[0, 0, 0],
        [0, 0, 0],
        [0, 1, 2]])[0m
[32m2025-11-22 21:33:52.274[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 153]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152]])[0m
[32m2025-11-22 21:33:52.274[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:52.274[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:52.287[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 12[0m
[32m2025-11-22 21:33:52.288[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([12, 1280])[0m
[32m2025-11-22 21:33:52.288[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[1, 2, 6]], device='cuda:2')[0m
[32m2025-11-22 21:33:52.288[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1,  8, 16]], device='cuda:2')[0m
[32m2025-11-22 21:33:52.317[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:52.328[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:52.340[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:52.346[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:52.353[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:52.354[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:52.370[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:52.372[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:52.415[0m | [31m[1mERROR   [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m362[0m - [31m[1mError during evaluation: 0. Please set `--verbosity=DEBUG` to get more information.[0m
[32m2025-11-22 21:33:52.447[0m | [31m[1mERROR   [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m362[0m - [31m[1mError during evaluation: 0. Please set `--verbosity=DEBUG` to get more information.[0m
[32m2025-11-22 21:33:52.626[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 464[0m
[32m2025-11-22 21:33:52.626[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([464, 1280])[0m
[32m2025-11-22 21:33:52.626[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[ 1,  8, 58]], device='cuda:0')[0m
[32m2025-11-22 21:33:52.627[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1, 64, 68]], device='cuda:0')[0m
[32m2025-11-22 21:33:52.681[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:52.703[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:52.727[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:52.729[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:53.249[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 88[0m
[32m2025-11-22 21:33:53.249[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 308x532 (836 patches), Resized: 336x560 (960 patches), Final APT: 88 patches[0m
[32m2025-11-22 21:33:53.266[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:53.270[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:53.270[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:53.271[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[ 1,  4, 22]]) after filter[0m
[32m2025-11-22 21:33:53.271[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 230]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 230])[0m
[32m2025-11-22 21:33:53.271[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[ 1,  4, 22]])[0m
[32m2025-11-22 21:33:53.273[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:53.273[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 22]), pos:tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0],
        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,
          1,  1,  1,  1],
        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10,  0,  1,  2,  3,  4,  5,  6,
          7,  8,  9, 10]])[0m
[32m2025-11-22 21:33:53.276[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 230]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  15,  15,  15,  26,  27,  28,  29,  30,
          31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,
          45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,
          59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,
          73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,
          87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100,
         101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,
         115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128,
         129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,
         143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
         157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170,
         171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,
         185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198,
         199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212,
         213, 214, 215, 216, 217, 218],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  16,  16,
          16,  16,  16,  16,  16,  16,  16,  16,  16,  26,  27,  28,  29,  30,
          31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,
          45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,
          59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,
          73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,
          87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100,
         101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,
         115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128,
         129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,
         143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
         157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170,
         171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,
         185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198,
         199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212,
         213, 214, 215, 216, 217, 218],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  15,  16,
          17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,  30,
          31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,
          45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,
          59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,
          73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,
          87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100,
         101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,
         115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128,
         129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,
         143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
         157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170,
         171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,
         185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198,
         199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212,
         213, 214, 215, 216, 217, 218]])[0m
[32m2025-11-22 21:33:53.277[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:53.277[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:53.360[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 88[0m
[32m2025-11-22 21:33:53.360[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([88, 1280])[0m
[32m2025-11-22 21:33:53.361[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[ 1,  4, 22]], device='cuda:0')[0m
[32m2025-11-22 21:33:53.361[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1, 24, 40]], device='cuda:0')[0m
[32m2025-11-22 21:33:53.412[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:53.425[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:53.448[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:53.449[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:53.596[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 24[0m
[32m2025-11-22 21:33:53.596[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 168x280 (240 patches), Resized: 168x280 (240 patches), Final APT: 24 patches[0m
[32m2025-11-22 21:33:53.603[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:53.606[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:53.606[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:53.607[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[1, 4, 6]]) after filter[0m
[32m2025-11-22 21:33:53.607[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 206]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 206])[0m
[32m2025-11-22 21:33:53.607[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[1, 4, 6]])[0m
[32m2025-11-22 21:33:53.607[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:53.608[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 6]), pos:tensor([[0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 1, 1],
        [0, 1, 2, 0, 1, 2]])[0m
[32m2025-11-22 21:33:53.611[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 206]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  18,  19,  20,  21,  22,  23,  24,
          25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,
          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,
          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,
          67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,
          81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,
          95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108,
         109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122,
         123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136,
         137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
         151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,
         165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178,
         179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192,
         193, 194, 195, 196, 197, 198, 199, 200, 201, 202],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  16,  16,  16,  18,  19,  20,  21,  22,  23,  24,
          25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,
          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,
          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,
          67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,
          81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,
          95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108,
         109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122,
         123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136,
         137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
         151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,
         165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178,
         179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192,
         193, 194, 195, 196, 197, 198, 199, 200, 201, 202],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,
          25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,
          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,
          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,
          67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,
          81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,
          95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108,
         109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122,
         123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136,
         137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
         151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,
         165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178,
         179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192,
         193, 194, 195, 196, 197, 198, 199, 200, 201, 202]])[0m
[32m2025-11-22 21:33:53.611[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:53.612[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:53.634[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 24[0m
[32m2025-11-22 21:33:53.634[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([24, 1280])[0m
[32m2025-11-22 21:33:53.634[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[1, 4, 6]], device='cuda:0')[0m
[32m2025-11-22 21:33:53.634[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1, 12, 20]], device='cuda:0')[0m
[32m2025-11-22 21:33:53.687[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:53.699[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:53.723[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:53.723[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:54.315[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 104[0m
[32m2025-11-22 21:33:54.315[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 280x672 (960 patches), Resized: 280x672 (960 patches), Final APT: 104 patches[0m
[32m2025-11-22 21:33:54.331[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:54.336[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:54.336[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:54.336[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[ 1,  4, 26]]) after filter[0m
[32m2025-11-22 21:33:54.336[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 204]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 204])[0m
[32m2025-11-22 21:33:54.336[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[ 1,  4, 26]])[0m
[32m2025-11-22 21:33:54.337[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:54.338[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 26]), pos:tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,
          1,  1,  1,  1,  1,  1,  1,  1],
        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12,  0,  1,  2,  3,  4,
          5,  6,  7,  8,  9, 10, 11, 12]])[0m
[32m2025-11-22 21:33:54.341[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 204]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  28,
          29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,
          43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,
          57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,
          71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,
          85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,
          99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,
         113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,
         127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140,
         141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
         155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,
         169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,
         183, 184, 185, 186, 187, 188, 189, 190],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  28,
          29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,
          43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,
          57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,
          71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,
          85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,
          99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,
         113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,
         127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140,
         141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
         155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,
         169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,
         183, 184, 185, 186, 187, 188, 189, 190],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,
          29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,
          43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,
          57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,
          71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,
          85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,
          99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,
         113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,
         127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140,
         141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
         155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,
         169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,
         183, 184, 185, 186, 187, 188, 189, 190]])[0m
[32m2025-11-22 21:33:54.342[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:54.342[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:54.427[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 104[0m
[32m2025-11-22 21:33:54.428[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([104, 1280])[0m
[32m2025-11-22 21:33:54.428[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[ 1,  4, 26]], device='cuda:0')[0m
[32m2025-11-22 21:33:54.428[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1, 20, 48]], device='cuda:0')[0m
[32m2025-11-22 21:33:54.480[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:54.493[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:54.516[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:54.518[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:54.578[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 12[0m
[32m2025-11-22 21:33:54.578[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 140x112 (80 patches), Resized: 168x112 (96 patches), Final APT: 12 patches[0m
[32m2025-11-22 21:33:54.582[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:54.587[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:54.587[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:54.587[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[1, 2, 6]]) after filter[0m
[32m2025-11-22 21:33:54.587[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 154]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 154])[0m
[32m2025-11-22 21:33:54.587[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[1, 2, 6]])[0m
[32m2025-11-22 21:33:54.588[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:54.588[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 3]), pos:tensor([[0, 0, 0],
        [0, 0, 0],
        [0, 1, 2]])[0m
[32m2025-11-22 21:33:54.590[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 154]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153]])[0m
[32m2025-11-22 21:33:54.591[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:54.591[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:54.601[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 12[0m
[32m2025-11-22 21:33:54.601[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([12, 1280])[0m
[32m2025-11-22 21:33:54.601[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[1, 2, 6]], device='cuda:0')[0m
[32m2025-11-22 21:33:54.601[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1, 12,  8]], device='cuda:0')[0m
[32m2025-11-22 21:33:54.652[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:54.662[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:54.685[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:54.687[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:56.921[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 404[0m
[32m2025-11-22 21:33:56.921[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 588x1232 (3696 patches), Resized: 616x1232 (3872 patches), Final APT: 404 patches[0m
[32m2025-11-22 21:33:56.976[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:56.979[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:56.979[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:56.980[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[  1,   2, 202]]) after filter[0m
[32m2025-11-22 21:33:56.980[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 251]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 251])[0m
[32m2025-11-22 21:33:56.980[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[  1,   2, 202]])[0m
[32m2025-11-22 21:33:56.982[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:56.983[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 101]), pos:tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100]])[0m
[32m2025-11-22 21:33:56.986[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 251]), llm_positions:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,
         168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,
         182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,
         196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,
         210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,
         224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,
         238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
          15,  15,  15,  15, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,
         168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,
         182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,
         196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,
         210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,
         224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,
         238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,
         168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,
         182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,
         196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,
         210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,
         224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,
         238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250]])[0m
[32m2025-11-22 21:33:56.987[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:56.987[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:57.330[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 404[0m
[32m2025-11-22 21:33:57.331[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([404, 1280])[0m
[32m2025-11-22 21:33:57.331[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[  1,   2, 202]], device='cuda:0')[0m
[32m2025-11-22 21:33:57.331[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[ 1, 44, 88]], device='cuda:0')[0m
[32m2025-11-22 21:33:57.383[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:57.396[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:57.419[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:57.420[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:57.443[0m | [31m[1mERROR   [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m362[0m - [31m[1mError during evaluation: 0. Please set `--verbosity=DEBUG` to get more information.[0m
[32m2025-11-22 21:33:58.067[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m474[0m - [1msum in imageprocessor: 1300[0m
[32m2025-11-22 21:33:58.067[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.image_processing_qwen2_vl[0m:[36m_preprocess[0m:[36m494[0m - [1mImage Stats: Original: 1764x1316 (11844 patches), Resized: 1792x1344 (12288 patches), Final APT: 1300 patches[0m
[32m2025-11-22 21:33:58.247[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m460[0m - [1mmodel_generate start here[0m
[32m2025-11-22 21:33:58.252[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1933[0m - [1mstart[0m
[32m2025-11-22 21:33:58.252[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1934[0m - [1mgrid_new_thw: True before filter[0m
[32m2025-11-22 21:33:58.252[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1937[0m - [1mgrid_new_thw: tensor([[ 1, 26, 50]]) after filter[0m
[32m2025-11-22 21:33:58.252[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1347[0m - [1minput_ids shape:torch.Size([1, 465]), image_grid_thw shape:torch.Size([1, 3]),  attention_mask shape:torch.Size([1, 465])[0m
[32m2025-11-22 21:33:58.253[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1348[0m - [1mimage_grid_thw:tensor([[ 1, 26, 50]])[0m
[32m2025-11-22 21:33:58.255[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1405[0m - [1mspatial_merge_size:2[0m
[32m2025-11-22 21:33:58.260[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1421[0m - [1mpos shape:torch.Size([3, 325]), pos:tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0],
        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,
          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2,  2,
          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,
          2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,
          3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  4,
          4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,
          5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,
          5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,
          6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  7,
          7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,
          7,  7,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,
          8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9,  9,  9,
          9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10,
         10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,
         10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,
         11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12,
         12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,
         12],
        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10,
         11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,  0,  1,  2,  3,
          4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,
         22, 23, 24,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,
         15, 16, 17, 18, 19, 20, 21, 22, 23, 24,  0,  1,  2,  3,  4,  5,  6,  7,
          8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,  0,
          1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,
         19, 20, 21, 22, 23, 24,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11,
         12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,  0,  1,  2,  3,  4,
          5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22,
         23, 24,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,
         16, 17, 18, 19, 20, 21, 22, 23, 24,  0,  1,  2,  3,  4,  5,  6,  7,  8,
          9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,  0,  1,
          2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,
         20, 21, 22, 23, 24,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12,
         13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,  0,  1,  2,  3,  4,  5,
          6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23,
         24]])[0m
[32m2025-11-22 21:33:58.260[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mget_rope_index[0m:[36m1431[0m - [1mllm_positions shape:torch.Size([3, 465]), llm_positions:tensor([[  0,   1,   2,  ..., 162, 163, 164],
        [  0,   1,   2,  ..., 162, 163, 164],
        [  0,   1,   2,  ..., 162, 163, 164]])[0m
[32m2025-11-22 21:33:58.261[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mprepare_inputs_for_generation[0m:[36m1944[0m - [1mend[0m
[32m2025-11-22 21:33:58.261[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:59.354[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1064[0m - [1mtotal patches after merge: 1300[0m
[32m2025-11-22 21:33:59.354[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1076[0m - [1mhidden_states shape:torch.Size([1300, 1280])[0m
[32m2025-11-22 21:33:59.355[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1077[0m - [1mgrid_new_thw: tensor([[ 1, 26, 50]], device='cuda:3')[0m
[32m2025-11-22 21:33:59.355[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1078[0m - [1mgrid_thw_original: tensor([[  1, 128,  96]], device='cuda:3')[0m
[32m2025-11-22 21:33:59.408[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:59.433[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1839[0m - [1mgeneration forward start here[0m
[32m2025-11-22 21:33:59.456[0m | [1mINFO    [0m | [36mtransformers.models.qwen2_vl.modeling_qwen2_vl[0m:[36mforward[0m:[36m1874[0m - [1mgeneration forward end here[0m
[32m2025-11-22 21:33:59.457[0m | [1mINFO    [0m | [36mlmms_eval.models.qwen2_vl[0m:[36mgenerate_until[0m:[36m477[0m - [1mmodel_generate end here[0m
[32m2025-11-22 21:33:59.481[0m | [31m[1mERROR   [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m362[0m - [31m[1mError during evaluation: 0. Please set `--verbosity=DEBUG` to get more information.[0m
