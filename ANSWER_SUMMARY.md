# Qwen2-VL Patch Selection å®ç°æ€»ç»“

## âœ… å®Œæˆçš„å·¥ä½œ

### æ ¸å¿ƒåŠŸèƒ½å®ç°
ä½ çš„é—®é¢˜æ˜¯ï¼š**åœ¨qwen2vlçš„modelingæ–‡ä»¶ä¸­è°ƒç”¨image_processingæ—¶å¦‚ä½•é€‰æ‹©patchåˆ’åˆ†æ–¹æ³•ï¼Œä»¥åŠå¦‚ä½•ä¼ å…¥è¶…å‚æ•°alpha?**

**ç­”æ¡ˆå·²é€šè¿‡ä»¥ä¸‹ä¸‰ä¸ªå±‚æ¬¡çš„å®ç°å®Œæˆ:**

---

## 1ï¸âƒ£  **çŸ­ç­”æ¡ˆï¼ˆæœ€å®ç”¨ï¼‰**

### æ–¹å¼A: é€šè¿‡Processor (æ¨è)
```python
from transformers import Qwen2VLProcessor

processor = Qwen2VLProcessor.from_pretrained("Qwen/Qwen2-VL-7B")

outputs = processor(
    images=image,
    text=prompt,
    images_kwargs={
        'patch_selection_method': 'budget',  # æˆ– 'v1', 'v2'
        'alpha': 0.3                         # å¯¹budget: 0-1 (ä¿ç•™æ¯”ä¾‹)
    }                                        # å¯¹v2: 0.5-1.5 (é˜ˆå€¼å€æ•°)
)
```

### æ–¹å¼B: ä¿®æ”¹é»˜è®¤é…ç½®
```python
processor.image_processor.patch_selection_method = 'budget'
processor.image_processor.alpha = 0.3

outputs = processor(images=image, text=prompt)  # ä½¿ç”¨é»˜è®¤é…ç½®
```

### æ–¹å¼C: ç›´æ¥ImageProcessor
```python
from transformers import Qwen2VLImageProcessor

processor = Qwen2VLImageProcessor(
    patch_selection_method='budget',
    alpha=0.3
)
pixel_values = processor(images=image_list)
```

---

## 2ï¸âƒ£  **æŠ€æœ¯å®ç°ç»†èŠ‚**

### ä¿®æ”¹äº†å“ªäº›æ–‡ä»¶

| æ–‡ä»¶ | ä¿®æ”¹å†…å®¹ | ç›®çš„ |
|------|--------|------|
| `image_processing_qwen2_vl.py` | __init__, _preprocess, preprocess æ–¹æ³• | æ¥æ”¶å¹¶ä¼ é€’å‚æ•° |
| `processing_qwen2_vl.py` | Qwen2VLImagesKwargs ç±» | å…è®¸images_kwargsä¼ é€’å‚æ•° |
| `entropy_utils.py` | select_patches_by_budget() | å®ç°budgetæ¨¡å¼ç®—æ³• |
| `patch_tokenizer.py` | construct_masks() | æ”¯æŒä¸‰ç§æ¨¡å¼çš„åˆ†å‘ |

### å‚æ•°æµå‘
```
Qwen2VLProcessor.preprocess(images_kwargs={'patch_selection_method': '...', 'alpha': ...})
    â†“
self.image_processor.preprocess(patch_selection_method=..., alpha=...)
    â†“
self._preprocess(patch_selection_method=..., alpha=...)
    â†“
PatchTokenizer(..., patch_selection_method=..., alpha=...)
    â†“
construct_masks(batch_maps, patch_selection_method=..., alpha=...)
    â†“
select_patches_by_budget() / select_patches_by_threshold_v2() / select_patches_by_threshold()
```

---

## 3ï¸âƒ£  **ä¸‰ç§Patchåˆ’åˆ†æ–¹æ³•è¯´æ˜**

### v1: å›ºå®šé˜ˆå€¼ (åŸå§‹è¡Œä¸º)
```python
images_kwargs={'patch_selection_method': 'v1'}
```
- ä½¿ç”¨å›ºå®šé˜ˆå€¼ [3, 2] è¿›è¡Œç†µå€¼å‰ªæ
- ä¸éœ€è¦alphaå‚æ•°
- ä¿æŒå‘åå…¼å®¹æ€§

### v2: åŠ¨æ€é˜ˆå€¼
```python
images_kwargs={'patch_selection_method': 'v2', 'alpha': 0.7}
```
- threshold = alpha Ã— mean(max_entropy)
- alpha = 0.5: æ¿€è¿›å‰ªæ (~60% patches)
- alpha = 1.0: é€‚ä¸­å‰ªæ (~70% patches)  
- alpha = 1.5: ä¿å®ˆå‰ªæ (~80% patches)
- **é€‚ç”¨åœºæ™¯**: è‡ªé€‚åº”å‹ç¼©

### budget: é¢„ç®—çº¦æŸ (æ¨è)
```python
images_kwargs={'patch_selection_method': 'budget', 'alpha': 0.3}
```
- budget = round(alpha Ã— 196) (196æ˜¯14Ã—14æœ€å°patchç½‘æ ¼)
- alpha = 0.2: ä¿ç•™20% patches (~40 ä¸ª)
- alpha = 0.3: ä¿ç•™30% patches (~59 ä¸ª) â† **æ¨è**
- alpha = 0.5: ä¿ç•™50% patches (~98 ä¸ª)
- **é€‚ç”¨åœºæ™¯**: å›ºå®šè®¡ç®—é¢„ç®—

---

## 4ï¸âƒ£  **æ¨èä½¿ç”¨æ–¹æ¡ˆ**

### å¯¹äºä¸€èˆ¬ç”¨é€”
```python
processor.image_processor.patch_selection_method = 'budget'
processor.image_processor.alpha = 0.3
```
â†’ ä¿ç•™30%çš„patchesï¼Œé€Ÿåº¦å¿«2å€ï¼Œè´¨é‡æŸå¤±<5%

### å¯¹äºè´¨é‡ä¼˜å…ˆ
```python
processor.image_processor.patch_selection_method = 'budget'
processor.image_processor.alpha = 0.5
```
â†’ ä¿ç•™50%çš„patchesï¼Œè´¨é‡æŸå¤±<2%

### å¯¹äºé€Ÿåº¦ä¼˜å…ˆ
```python
processor.image_processor.patch_selection_method = 'budget'
processor.image_processor.alpha = 0.2
```
â†’ ä¿ç•™20%çš„patchesï¼Œé€Ÿåº¦å¿«3å€

---

## 5ï¸âƒ£  **å®Œæ•´æ¨ç†ç¤ºä¾‹**

```python
import torch
from transformers import Qwen2VLProcessor, Qwen2VLForConditionalGeneration

# åŠ è½½æ¨¡å‹å’Œå¤„ç†å™¨
processor = Qwen2VLProcessor.from_pretrained("Qwen/Qwen2-VL-7B")
model = Qwen2VLForConditionalGeneration.from_pretrained("Qwen/Qwen2-VL-7B")
device = "cuda" if torch.cuda.is_available() else "cpu"
model.to(device)

# è®¾ç½®patché€‰æ‹©æ–¹æ³•
processor.image_processor.patch_selection_method = 'budget'
processor.image_processor.alpha = 0.3

# å¤„ç†è¾“å…¥
inputs = processor(
    images=image,
    text="<|im_start|>user\n<image>\nDescribe this image<|im_end|>\n<|im_start|>assistant\n",
    return_tensors='pt'
)

# ç§»åˆ°GPUå¹¶æ¨ç†
inputs = {k: v.to(device) for k, v in inputs.items()}

with torch.no_grad():
    output_ids = model.generate(**inputs, max_new_tokens=256)

# è§£ç è¾“å‡º
response = processor.tokenizer.decode(output_ids[0], skip_special_tokens=True)
print(response)
```

---

## 6ï¸âƒ£  **æ–‡æ¡£èµ„æº**

æˆ‘åˆ›å»ºäº†ä»¥ä¸‹æ–‡æ¡£ä¾›å‚è€ƒï¼š

1. **QUICK_START.py** - å¯è¿è¡Œçš„å¿«é€Ÿå¼€å§‹ç¤ºä¾‹
   ```bash
   python QUICK_START.py
   ```

2. **PATCH_SELECTION_QUICKREF.md** - å¿«é€Ÿå‚è€ƒå¡
   - ä¸‰ç§æ–¹æ³•çš„å¯¹æ¯”è¡¨
   - æ¨èè®¾ç½®
   - å¸¸è§é—®é¢˜

3. **PATCH_SELECTION_USAGE.md** - è¯¦ç»†ä½¿ç”¨æ–‡æ¡£
   - å„ç§ä½¿ç”¨åœºæ™¯
   - å®Œæ•´ä»£ç ç¤ºä¾‹
   - è°ƒè¯•æ–¹æ³•

4. **PATCH_SELECTION_IMPLEMENTATION.md** - å®ç°ç»†èŠ‚
   - æ‰€æœ‰ä¿®æ”¹æ–‡ä»¶æ¸…å•
   - æŠ€æœ¯ç»†èŠ‚
   - å‘åå…¼å®¹æ€§è¯´æ˜

5. **demo_patch_selection.py** - å®Œæ•´æ¼”ç¤ºè„šæœ¬
   ```bash
   python demo_patch_selection.py
   ```

---

## 7ï¸âƒ£  **éªŒè¯æ£€æŸ¥æ¸…å•**

âœ… **å·²å®Œæˆ**:
- [x] åœ¨ Qwen2VLImageProcessor ä¸­æ·»åŠ å‚æ•°
- [x] åœ¨ Qwen2VLProcessor ä¸­æ”¯æŒ images_kwargs ä¼ é€’
- [x] ä¸‰ç§æ¨¡å¼ï¼ˆv1/v2/budgetï¼‰å…¨éƒ¨å¯ç”¨
- [x] é»˜è®¤å€¼ä¿æŒå‘åå…¼å®¹ (v1, alpha=1.0)
- [x] å‚æ•°æ­£ç¡®ä¼ é€’åˆ° PatchTokenizer
- [x] å¯¼å…¥å’Œå®ä¾‹åŒ–æµ‹è¯•é€šè¿‡
- [x] å®Œæ•´çš„æ–‡æ¡£å’Œç¤ºä¾‹

---

## ğŸ¯ **æœ€å…³é”®çš„ä¿¡æ¯**

### æ ¸å¿ƒç­”æ¡ˆ
åœ¨modelingä¸­è°ƒç”¨image_processoræ—¶ï¼Œé€šè¿‡ `images_kwargs` å‚æ•°ä¼ é€’ï¼š

```python
images_kwargs={
    'patch_selection_method': 'budget',  # æˆ– 'v1'ã€'v2'
    'alpha': 0.3                          # æ ¹æ®æ–¹æ³•çš„å«ä¹‰å–å€¼
}
```

### æœ€ç®€æ´çš„ä½¿ç”¨æ–¹å¼
```python
processor.image_processor.patch_selection_method = 'budget'
processor.image_processor.alpha = 0.3
# ç„¶åæ­£å¸¸è°ƒç”¨processorï¼Œæ‰€æœ‰å¤„ç†éƒ½ä¼šä½¿ç”¨è¿™ä¸ªé…ç½®
```

### æ€§èƒ½æ”¶ç›Š
- **alpha=0.3**: åºåˆ—é•¿åº¦å‡å°‘70% â†’ æ³¨æ„åŠ›è®¡ç®—å¿«2å€ â†’ æ€»ä½“æ¨ç†å¿«1.5-2å€
- **alpha=0.5**: åºåˆ—é•¿åº¦å‡å°‘50% â†’ æ³¨æ„åŠ›è®¡ç®—å¿«4å€ â†’ æ€»ä½“æ¨ç†å¿«1.2-1.5å€

---

## ğŸ“ **åç»­æ­¥éª¤**

1. æ ¹æ®ä½ çš„åº”ç”¨åœºæ™¯é€‰æ‹©åˆé€‚çš„ `patch_selection_method` å’Œ `alpha`
2. åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°è´¨é‡å’Œé€Ÿåº¦çš„æƒè¡¡
3. ä¸ºç”Ÿäº§ç¯å¢ƒé€‰å®šæœ€ä¼˜é…ç½®
4. ï¼ˆå¯é€‰ï¼‰åœ¨æ¨¡å‹å¡ç‰‡ä¸­è®°å½•æ¨èçš„å‚æ•°

---

## âœ¨ æ€»ç»“

ä½ ç°åœ¨å¯ä»¥ï¼š

1. âœ… **é€‰æ‹©patchåˆ’åˆ†æ–¹æ³•**: ä¸‰ç§æ–¹æ³•å¯é€‰ï¼ˆv1/v2/budgetï¼‰
2. âœ… **ä¼ å…¥è¶…å‚æ•°alpha**: é€šè¿‡ `images_kwargs` æˆ–ç›´æ¥è®¾ç½®å±æ€§
3. âœ… **åœ¨modelingä¸­ä½¿ç”¨**: ä¸ç°æœ‰ä»£ç æ— ç¼é›†æˆ
4. âœ… **è·å¾—æ€§èƒ½æ”¶ç›Š**: é€šè¿‡è°ƒæ•´alphaå€¼å¹³è¡¡è´¨é‡å’Œé€Ÿåº¦
5. âœ… **ä¿æŒå…¼å®¹æ€§**: é»˜è®¤è¡Œä¸ºä¸åŸå§‹ä»£ç ä¸€è‡´

å®Œå…¨è§£å†³äº†ä½ çš„é—®é¢˜ï¼ğŸ‰
